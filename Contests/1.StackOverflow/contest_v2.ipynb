{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.sparse as sps\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, TfidfTransformer, CountVectorizer\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import operator\n",
    "from collections import OrderedDict\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.collocations import BigramCollocationFinder\n",
    "from nltk.metrics import BigramAssocMeasures\n",
    "from nltk.probability import FreqDist, ConditionalFreqDist\n",
    "from importlib import reload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_path = 'train-contest.csv'\n",
    "data = pd.read_csv(train_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 733,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# data.to_csv(\"new_data.csv\", columns=['PartsOfSpeach'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "new_data = pd.read_csv(\"new_data.csv\", parse_dates=True, dayfirst=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "reasons = pd.read_csv('reason.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data['Reason'] = reasons['OpenStatus']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data['PartsOfSpeach'] = new_data['PartsOfSpeach']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"['IN', 'NNP', 'NNP', 'NN', 'NN', 'PRP', 'VBP', 'VBN', 'JJ', 'NN', 'NNP', 'DT', 'NNP', 'NN', 'IN', 'JJ', 'NN', 'NN', 'IN', 'PRP$', 'NNP', 'NN', 'NN', 'PRP', 'VBP', 'VBN', 'NNP', 'NNP', 'VBP', 'RB', 'VB', 'DT', 'NNP', 'NN', 'CC', 'IN', 'WP', 'PRP', 'VBN', 'NN', 'NN', 'VBP', 'VBZ', 'RP', 'NN', 'IN', 'NN', 'PRP', 'VBP', 'NN', 'IN', 'NN', 'CC', 'PRP', 'MD', 'RB', 'VB', 'PRP', 'IN', 'DT', 'JJ', 'NN', 'NN', 'NN', 'CC', 'DT', 'NN', 'NN', 'IN', 'NNP', 'PRP', 'MD', 'VB', 'CD', 'NN', 'IN', 'NN', 'IN', 'DT', 'NN', 'IN', 'DT', 'NNP', 'NNP', 'NN', 'CC', 'PRP', 'MD', 'VB', 'JJ', 'NN', 'IN', 'DT', 'JJ', 'NN', 'CC', 'DT', 'JJ', 'NN', 'PRP', 'CC', 'VB', 'DT', 'JJ', 'NN', 'IN', 'DT', 'NN', 'NNP', 'DT', 'NN', 'MD', 'VB', 'VB', 'PRP', 'TO', 'DT', 'NN', 'NN', 'CC', 'IN', 'PRP', 'VBD', 'RB', 'VB', 'PRP', 'MD', 'VB', 'DT', 'NN', 'IN', 'PRP', 'PRP', 'VBP', 'IN', 'DT', 'NNP', 'NN', 'IN', 'NNP', 'CC', 'PRP', 'VBP', 'IN', 'NNP', 'RB', 'VBD', 'DT', 'NNP', 'NN', 'WDT', 'VBP', 'DT', 'NN', 'IN', 'NN', 'IN', 'DT', 'JJ', 'NN', 'NNP', 'NN', 'CC', 'NNP', 'VBP', 'RB', 'VB', 'IN', 'DT', 'NN', 'WDT', 'MD', 'VB', 'JJ', 'NNP', 'NN', 'NNP', 'VBZ', 'DT', 'NN', 'IN', 'IN', 'DT', 'NN', 'TO', 'DT', 'NN', 'NNP', 'VBP', 'PRP', 'VB', 'DT', 'NN', 'IN', 'DT', 'NNP', 'NN', 'NN', 'NN', 'PRP', 'VBP', 'IN', 'DT', 'NN', 'NN', 'IN', 'NN', 'CC', 'WP', 'IN', 'PRP', 'VBZ', 'JJ', 'CC', 'PRP', 'VBP', 'TO', 'VB', 'DT', 'NNP', 'NN', 'NNP', 'EX', 'DT', 'JJ', 'NN', 'TO', 'VB', 'DT', 'NN', 'CC', 'VBP', 'PRP', 'VB', 'TO', 'VB', 'TO', 'DT', 'NNP', 'NNP', 'IN', 'DT', 'NN']\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.PartsOfSpeach[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Извлечение информации"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разбиваем Body на текст и код"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data['Code'] = data.BodyMarkdown.apply(lambda text: \" \".join([line for line in text.split('\\n') if \n",
    "                                                     line.startswith('    ') or line.startswith('\\t')]))\n",
    "data['Text'] = data.BodyMarkdown.apply(lambda text: \" \".join([line for line in text.split('\\n') if not\n",
    "                                                     line.startswith('    ') and not line.startswith('\\t')]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data['SplittedCode'] = data.Code.apply(lambda code: re.sub(\"[^a-z]\", \" \", code.lower()).split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data['CodeLen'] = data.SplittedCode.apply(len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Текст"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Несколько статистик о тексте"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# data.Text = data.Text.apply(lambda text: ' '.join(text))\n",
    "data['NonWords'] = data.Text.apply(lambda text: len(re.findall('[A-Za-z\\d_]+[ \\.\\?\\,\\!]', text)))\n",
    "data['Digits'] = data.Text.apply(lambda text: len(re.findall('\\d+', text)))\n",
    "data['NonAlNums'] = data.Text.apply(lambda text: len(re.findall('[^\\w\\s]+', text)))\n",
    "data['URLs'] = data.Text.apply(lambda text: len(re.findall('https?://', text)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data['Text'] = data.Text.apply(nltk.word_tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data['PureText'] = data.Text.apply(lambda text: [word for word in text if word[0].isalpha()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data['NumWords'] = data.PureText.apply(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data.Title = data.Title.apply(nltk.word_tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data['Sentences'] = data.Text.apply(lambda x:nltk.sent_tokenize(\" \".join(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data['NumSentences'] = data.Sentences.apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data['Questions'] = data.Sentences.apply(lambda x: len([sent for sent in x if sent[-1]=='?']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data['Questions_ratio'] = data.Questions / data.NumSentences\n",
    "data.Questions_ratio = data.Questions_ratio.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data['NumLastQuestions'] = data.Sentences.apply(lambda text:\n",
    "                    [sent[-1] for sent in text[-5:]].count('?'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.33333333333333331"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.Questions_ratio[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"In My VB.NET web page , I have this standard event . Note the `` Handles '' clause on teh event declaration . In my C # web app , I have this : Since C # does n't have a `` Handles '' equivalent and from what I 've seen , event handlers are wired up using delegate += syntax , I was looking for this , but I could not foind it in the aspx page , aspx.cs file or the aspx.designer.cs file . In VB , I would have two drop down lists at the top of the Code Editor window and I could select any object on the web form or the web form itself and see the possible events for the object . Selecting the event would either take me to the event handler or if it did n't exists , it would create the stub for me . I know that the Properties window in C # ( and I think in VB , too ) has an Event tab that shows the list of events for the selected object GUI object , but `` Page '' does n't appear as an object that can be selected . 1 . Where does C # define the hooking up of the event to the handler ? 2 . How do I generate a stub for the Page event handler routine ? I know that the handle appears by default , but what if it is deleted or I want to add a Page_initialize code ? Is there an easy way to get the stub or do I need to go to the Object Browser for the syntax ?\""
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\" \".join(data.Text[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Пользователь"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.4/lib/python3.4/site-packages/pandas/core/generic.py:2177: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self[name] = value\n"
     ]
    }
   ],
   "source": [
    "data['PostCreationDate'] = data['PostCreationDate'].apply(lambda x: time.strptime(x[:10], \"%m/%d/%Y\"))\n",
    "data['OwnerCreationDate'] = data['OwnerCreationDate'].apply(lambda x: x if (x != '2008-09-01') else '01/09/2008')\n",
    "data['OwnerCreationDate'] = data['OwnerCreationDate'].apply(lambda x: time.strptime(x[:10], \"%m/%d/%Y\"))\n",
    "data['OwnerCreationDate'] = data['OwnerCreationDate'].apply(lambda x: time.mktime(x) / 86400)\n",
    "data['PostCreationDate'] = data['PostCreationDate'].apply(lambda x: time.mktime(x) / 86400)\n",
    "data['DaysBeforePost'] = data['PostCreationDate'] - data['OwnerCreationDate']\n",
    "data[data['DaysBeforePost'] < 0].DaysBeforePost = -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Теги"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data['Tags'] = list(zip(data.Tag1.fillna(\"\"), \n",
    "                               data.Tag2.fillna(\"\"), data.Tag3.fillna(\"\"), \n",
    "                               data.Tag4.fillna(\"\"), data.Tag5.fillna(\"\"))) \n",
    "data['Tags'] = data['Tags'].apply(lambda x: (\" \".join(x).lower().split()))\n",
    "data['EmptyTags'] = data['Tags'].apply(lambda tagset: len(tagset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Разобьем данные на тестовую и обучающую выборки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data = data[:70000]\n",
    "test_data = data[70000:]\n",
    "train_columns = [col for col in data.columns if col != 'OpenStatus' and col != 'PostClosedDate']\n",
    "x_tr = train_data[train_columns]\n",
    "y_tr = train_data.OpenStatus\n",
    "x_test = test_data[train_columns]\n",
    "y_test = test_data.OpenStatus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#TF-IDF текстов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vect = TfidfVectorizer(lowercase=False, tokenizer=lambda doc: doc)\n",
    "text_tr_tfidf = vect.fit_transform(x_tr.Text)\n",
    "text_test_tfidf = vect.transform(x_test.Text)\n",
    "title_tr_tfidf = vect.fit_transform(x_tr.Title)\n",
    "title_test_tfidf = vect.transform(x_test.Title)\n",
    "tag_tr_tfidf = vect.fit_transform(x_tr.Tags)\n",
    "tag_test_tfidf = vect.transform(x_test.Tags)\n",
    "code_tr_tfidf = vect.fit_transform(x_tr.SplittedCode)\n",
    "code_test_tfidf = vect.transform(x_test.SplittedCode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.4/lib/python3.4/site-packages/pandas/core/generic.py:2177: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self[name] = value\n"
     ]
    }
   ],
   "source": [
    "x_tr.Title = x_tr.Title.apply(\" \".join)\n",
    "x_test.Title = x_test.Title.apply(\" \".join)\n",
    "bigram_vectorizer = CountVectorizer(ngram_range=(2,2), token_pattern=r'\\b\\w+\\b', min_df=1)\n",
    "bititle_tr = bigram_vectorizer.fit_transform(x_tr.Title)\n",
    "bititle_test = bigram_vectorizer.transform(x_test.Title)\n",
    "transformer = TfidfTransformer()\n",
    "bititle_test = transformer.fit_transform(bititle_test)\n",
    "bititle_tr = transformer.fit_transform(bititle_tr)\n",
    "x_tr.Title = x_tr.Title.apply(lambda text: text.split())\n",
    "x_test.Title = x_test.Title.apply(lambda text: text.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.4/lib/python3.4/site-packages/pandas/core/generic.py:2177: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self[name] = value\n"
     ]
    }
   ],
   "source": [
    "x_tr.PureText = x_tr.PureText.apply(\" \".join)\n",
    "x_test.PureText = x_test.PureText.apply(\" \".join)\n",
    "bigram_vectorizer = CountVectorizer(ngram_range=(2,2), token_pattern=r'\\b\\w+\\b', min_df=1)\n",
    "bigrams_tr = bigram_vectorizer.fit_transform(x_tr.PureText)\n",
    "bigrams_test = bigram_vectorizer.transform(x_test.PureText)\n",
    "transformer = TfidfTransformer()\n",
    "bigrams_test = transformer.fit_transform(bigrams_test)\n",
    "bigrams_tr = transformer.fit_transform(bigrams_tr)\n",
    "x_tr.PureText = x_tr.PureText.apply(lambda text: text.split())\n",
    "x_test.PureText = x_test.PureText.apply(lambda text: text.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vect = TfidfVectorizer(lowercase=False, tokenizer=lambda doc: doc)\n",
    "pos_tr_tfidf = vect.fit_transform(x_tr.PartsOfSpeach)\n",
    "pos_test_tfidf = vect.transform(x_test.PartsOfSpeach)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.4/lib/python3.4/site-packages/pandas/core/generic.py:2177: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self[name] = value\n"
     ]
    }
   ],
   "source": [
    "x_tr.PartsOfSpeach = x_tr.PartsOfSpeach.apply(\" \".join)\n",
    "x_test.PartsOfSpeach = x_test.PartsOfSpeach.apply(\" \".join)\n",
    "bigram_vectorizer = CountVectorizer(ngram_range=(2,2), token_pattern=r'.', min_df=1)\n",
    "bipos_tr = bigram_vectorizer.fit_transform(x_tr.PartsOfSpeach)\n",
    "bipos_test = bigram_vectorizer.transform(x_test.PartsOfSpeach)\n",
    "transformer = TfidfTransformer()\n",
    "bipos_test = transformer.fit_transform(bipos_test)\n",
    "bipos_tr = transformer.fit_transform(bipos_tr)\n",
    "x_tr.PartsOfSpeach = x_tr.PartsOfSpeach.apply(lambda text: text.split())\n",
    "x_test.PartsOfSpeach = x_test.PartsOfSpeach.apply(lambda text: text.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(70000, 13938)\n",
      "(70000, 43930)\n",
      "(70000, 220561)\n",
      "(70000, 112251)\n",
      "(70000, 1090637)\n",
      "(70000, 30)\n",
      "(70000, 57)\n",
      "(70000, 221033)\n"
     ]
    }
   ],
   "source": [
    "print(tag_tr_tfidf.shape)\n",
    "print(title_tr_tfidf.shape)\n",
    "print(text_tr_tfidf.shape)\n",
    "print(code_tr_tfidf.shape)\n",
    "print(bigrams_tr.shape)\n",
    "print(pos_tr_tfidf.shape)\n",
    "print(bipos_tr.shape)\n",
    "print(bititle_tr.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Функции для шкалирования"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def log_scaler(df):\n",
    "    new_df = df.copy()\n",
    "    quant = new_df.quantile(0.9)\n",
    "    if new_df.min() < 0:\n",
    "        new_df -= new_df.min()\n",
    "    new_df[new_df > quant] = np.log(new_df[new_df > quant] - quant + 1) + quant\n",
    "    return 0.5 + (new_df - new_df.mean()) / (new_df.std())\n",
    "\n",
    "def norm_scaler(df):\n",
    "    new_df = df.copy()\n",
    "    return 0.5 + (new_df - new_df.mean()) / new_df.std()\n",
    "\n",
    "def is_very_big(df):\n",
    "    new_df = df.copy()\n",
    "    quant = new_df.quantile(0.95)\n",
    "    new_df[new_df > quant] = 1\n",
    "    new_df[new_df < quant] = 0\n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    100000.000000\n",
       "mean          0.500000\n",
       "std           1.000000\n",
       "min          -0.445222\n",
       "25%          -0.445222\n",
       "50%           0.286462\n",
       "75%           1.018146\n",
       "max           3.213197\n",
       "Name: Questions_ratio, dtype: float64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm_scaler(data.Questions_ratio).describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " #Поэкспериментируем с текстом"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data['Excls_ratio'] = data.Sentences.apply(lambda text:\n",
    "                    [sent[-1] for sent in text].count('!')) / (data.NumWords+1)\n",
    "data['Statements_ratio'] = data.Sentences.apply(lambda text:\n",
    "                    [sent[-1] for sent in text].count('.')) / (data.NumWords+1)\n",
    "data.Statements_ratio = data.Statements_ratio.fillna(0)\n",
    "data.Excls_ratio = data.Excls_ratio.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data['Comma_ratio'] = data.Text.apply(lambda text: text.count(',')) / (data.NumWords+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data['AverageWordLen'] = data.Text.apply(lambda x: len(\" \".join(x))) / (data.NumWords+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data['AverageSentLen'] = data.Sentences.apply(len) / (data.NumWords+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# data['PartsOfSpeach'] = data.PureText.apply(lambda text: [word[1] for word in nltk.pos_tag(text)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    ['IN', 'NNP', 'NNP', 'NN', 'NN', 'PRP', 'VBP',...\n",
       "1    ['PRP', 'VBP', 'TO', 'VB', 'NNP', 'IN', 'NNP',...\n",
       "2    ['PRP$', 'NNP', 'NNP', 'VBZ', 'NN', 'IN', 'NNP...\n",
       "3    ['PRP', 'VBP', 'DT', 'JJ', 'NNP', 'NN', 'NN', ...\n",
       "4    ['NN', 'NN', 'TO', 'VB', 'JJ', 'NN', 'IN', 'NN...\n",
       "Name: PartsOfSpeach, dtype: object"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['PartsOfSpeach'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data = data[:70000]\n",
    "test_data = data[70000:]\n",
    "train_columns = [col for col in data.columns if col != 'OpenStatus' and col != 'PostClosedDate']\n",
    "x_tr = train_data[train_columns]\n",
    "y_tr = train_data.OpenStatus\n",
    "x_test = test_data[train_columns]\n",
    "y_test = test_data.OpenStatus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Попробуем вычислить попарные произведения признаков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calculate_products(x):\n",
    "    dim = x.shape[1]\n",
    "    print(dim)\n",
    "    for i in range(dim):\n",
    "        for j in range(dim):\n",
    "#             print(i, j)\n",
    "            x = np.hstack((x, (x[:, i] * x[:, j])[:, None]))\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Собираем признаки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "cols = ['CodeLen', 'NumWords', 'DaysBeforePost', 'NumSentences', 'Questions_ratio',  'NonWords', 'Digits', \n",
    "             'NonAlNums', 'EmptyTags', 'NumLastQuestions', 'ReputationAtPostCreation', \n",
    "             'OwnerUndeletedAnswerCountAtPostTime', 'Comma_ratio']\n",
    "cols_norm = cols\n",
    "# cols_norm = ['CodeLen']\n",
    "# cols_log = ['DaysBeforePost', 'ReputationAtPostCreation', 'OwnerUndeletedAnswerCountAtPostTime', ]\n",
    "cols_log = cols\n",
    "# cols_log =[]\n",
    "\n",
    "x_train_2 = np.array(norm_scaler(x_tr[cols_norm[0]]))[:, None]\n",
    "x_test_2 = np.array(norm_scaler(x_test[cols_norm[0]]))[:, None]\n",
    "for col in cols_norm[1:]:\n",
    "    x_train_2 = np.hstack((x_train_2, np.array(norm_scaler(x_tr[col]))[:, None]))\n",
    "    x_test_2 = np.hstack((x_test_2, np.array(norm_scaler(x_test[col]))[:, None]))\n",
    "for col in cols_log:\n",
    "    x_train_2 = np.hstack((x_train_2, np.array(log_scaler(x_tr[col]))[:, None]))\n",
    "    x_test_2 = np.hstack((x_test_2, np.array(log_scaler(x_test[col]))[:, None]))\n",
    "# for col in cols_big:\n",
    "#     x_train_2 = np.hstack((x_train_2, np.array(is_very_big(x_tr[col]))[:, None]))\n",
    "#     x_test_2 = np.hstack((x_test_2, np.array(is_very_big(x_test[col]))[:, None]))\n",
    "print(np.sum(np.isnan(x_test_2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# x_train_2 = sps.csr_matrix(sps.hstack((x_train_2, text_tr_tfidf, title_tr_tfidf, tag_tr_tfidf)))\n",
    "# x_test_2 = sps.csr_matrix(sps.hstack((x_test_2, text_test_tfidf, title_test_tfidf, tag_test_tfidf)))\n",
    "x_train_2 = sps.csr_matrix(sps.hstack((x_train_2, tag_tr_tfidf, title_tr_tfidf, text_tr_tfidf, code_tr_tfidf, \n",
    "                                       small_bigrams_tr_tfidf, bititle_tr)))\n",
    "x_test_2 = sps.csr_matrix(sps.hstack((x_test_2, tag_test_tfidf, title_test_tfidf, text_test_tfidf, code_test_tfidf, \n",
    "                                      small_bigrams_test_tfidf, bititle_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.850614880441\n"
     ]
    }
   ],
   "source": [
    "clf_linear = LogisticRegression()\n",
    "clf_linear.fit(x_train_2, y_tr)\n",
    "predicted_y_test = clf_linear.predict_proba(x_test_2)\n",
    "print(roc_auc_score(y_test, predicted_y_test[:, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70000, 68)"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30000, 500000)"
      ]
     },
     "execution_count": 409,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "small_bigrams_test_tfidf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "open                   2990\n",
       "not a real question    1970\n",
       "off topic               943\n",
       "not constructive        760\n",
       "too localized           443\n",
       "dtype: int64"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test[y_test != np.round(predicted_y_test[:, 1])].Reason.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cols = ['CodeLen', 'NumWords', 'DaysBeforePost', 'NumSentences', 'Questions_ratio',  'NonWords', 'Digits', \n",
    "             'NonAlNums', 'EmptyTags', 'NumLastQuestions', 'ReputationAtPostCreation', \n",
    "             'OwnerUndeletedAnswerCountAtPostTime', 'Comma_ratio']\n",
    "cols_norm = cols\n",
    "cols_log = cols\n",
    "\n",
    "x_train_knn = np.array(norm_scaler(x_tr[cols_norm[0]]))[:, None]\n",
    "x_test_knn = np.array(norm_scaler(x_test[cols_norm[0]]))[:, None]\n",
    "for col in cols_norm[1:]:\n",
    "    x_train_knn = np.hstack((x_train_knn, np.array(norm_scaler(x_tr[col]))[:, None]))\n",
    "    x_test_knn = np.hstack((x_test_knn, np.array(norm_scaler(x_test[col]))[:, None]))\n",
    "for col in cols_log:\n",
    "    x_train_knn = np.hstack((x_train_knn, np.array(log_scaler(x_tr[col]))[:, None]))\n",
    "    x_test_knn = np.hstack((x_test_knn, np.array(log_scaler(x_test[col]))[:, None]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_train_knn = sps.csr_matrix(sps.hstack((x_train_knn, small_tag_tr_tfidf, small_text_tr_tfidf, \n",
    "                                         small_title_tr_tfidf, small_code_tr_tfidf, small_bigrams_tr_tfidf)))\n",
    "x_test_knn = sps.csr_matrix(sps.hstack((x_test_knn, small_tag_test_tfidf, small_text_test_tfidf,\n",
    "                                       small_title_test_tfidf, small_code_test_tfidf, small_bigrams_test_tfidf)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30000, 8026)"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test_knn.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-281-0158697c28f9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRandomForestClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m700\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train_knn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_tr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mforest_prediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test_knn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mforest_prediction_saver\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mforest_prediction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroc_auc_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforest_prediction\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.4/lib/python3.4/site-packages/sklearn/ensemble/forest.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    271\u001b[0m                     \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrees\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m                     verbose=self.verbose, class_weight=self.class_weight)\n\u001b[0;32m--> 273\u001b[0;31m                 for i, t in enumerate(trees))\n\u001b[0m\u001b[1;32m    274\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m             \u001b[0;31m# Collect newly grown trees\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.4/lib/python3.4/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    664\u001b[0m                 \u001b[0;31m# consumption.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    665\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 666\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    667\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    668\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.4/lib/python3.4/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    516\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    517\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 518\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    519\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexception\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.4/lib/python3.4/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    591\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    592\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 593\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    594\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mready\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.4/lib/python3.4/multiprocessing/pool.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    588\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    589\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 590\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    591\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    592\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.4/lib/python3.4/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    551\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 553\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    554\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    555\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.4/lib/python3.4/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    288\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    289\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 290\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    291\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "clf = RandomForestClassifier(n_estimators=700, n_jobs=-1)\n",
    "clf.fit(x_train_knn, y_tr)\n",
    "forest_prediction = clf.predict_proba(x_test_knn)\n",
    "forest_prediction_saver = np.copy(forest_prediction)\n",
    "print(roc_auc_score(y_test, forest_prediction[:, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 701,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.809455254504\n",
      "163.25106382369995\n",
      "0.818723316739\n",
      "1063.5971138477325\n",
      "0.818734683422\n",
      "2344.9134528636932\n",
      "0.819456873351\n",
      "3795.4877338409424\n",
      "0.819156810697\n",
      "5641.991401910782\n",
      "0.82004473642\n",
      "7642.447065830231\n"
     ]
    }
   ],
   "source": [
    "n_list = [100, 500, 700, 800, 1000, 1100]\n",
    "start = time.time()\n",
    "for n in n_list:\n",
    "    clf = RandomForestClassifier(n_estimators=n, n_jobs=-1)\n",
    "    clf.fit(x_train_knn, y_tr)\n",
    "    forest_prediction = clf.predict_proba(x_test_knn)\n",
    "    print(roc_auc_score(y_test, forest_prediction[:, 1]))\n",
    "    print(time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.850614880441\n",
      "0.852528938753\n",
      "0.853896487389\n",
      "0.854528161632\n",
      "0.854116227705\n",
      "0.852262633925\n",
      "0.848393799465\n",
      "0.841868418957\n",
      "0.832029009233\n",
      "0.818387747367\n"
     ]
    }
   ],
   "source": [
    "for w in np.linspace(0, 1, 10):\n",
    "    print(roc_auc_score(y_test, w * forest_prediction[:, 1] + (1 - w) * predicted_y_test[:, 1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Исследуем ошибки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def plot_results(prediction):\n",
    "    reasons_lst = ['open', 'not a real question', 'off topic', 'not constructive', 'too localized']\n",
    "#     print(len(x_test[y_test != np.round(prediction[:, 1])][x_test.Reason == 'open']))\n",
    "    sizes = [len(x_test[(y_test != np.round(prediction[:, 1])) & \n",
    "                        (x_test.Reason == reason)])/len(y_test[x_test.Reason == reason])\n",
    "             for reason in reasons_lst]\n",
    "    colors = ['yellowgreen', 'gold', 'lightskyblue', 'lightcoral', 'red']\n",
    "    explode = (0, 0, 0, 0, 0)  # only \"explode\" the 2nd slice (i.e. 'Hogs')\n",
    "#     labels = reasons_lst\n",
    "\n",
    "#     plt.pie(sizes, explode=explode, labels=labels, colors=colors,\n",
    "#         autopct='%1.1f%%', shadow=True, startangle=90)\n",
    "    for i in range(5):\n",
    "        print(reasons_lst[i],':', sizes[i])\n",
    "#     plt.bar(range(5), sizes)\n",
    "#     plt.xticks([0.5, 1.5, 2.5, 3.5, 4.5], reasons_lst, rotation='vertical')\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "open : 0.25455405725100544\n",
      "not a real question : 0.2559865900383142\n",
      "off topic : 0.25399201596806387\n",
      "not constructive : 0.24653113907712165\n",
      "too localized : 0.25161290322580643\n"
     ]
    }
   ],
   "source": [
    "plot_results(forest_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 646,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "open : 0.22513997318823437\n",
      "not a real question : 0.22629310344827586\n",
      "off topic : 0.21756487025948104\n",
      "not constructive : 0.22587931590835753\n",
      "too localized : 0.22688172043010751\n"
     ]
    }
   ],
   "source": [
    "plot_results(0.7 * predicted_y_test + 0.3*forest_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "open : 0.22884630549641197\n",
      "not a real question : 0.22796934865900384\n",
      "off topic : 0.22080838323353294\n",
      "not constructive : 0.2281381090674411\n",
      "too localized : 0.22365591397849463\n"
     ]
    }
   ],
   "source": [
    "plot_results(predicted_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 653,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "open : 0.24414478353442157\n",
      "not a real question : 0.24113984674329503\n",
      "off topic : 0.2465069860279441\n",
      "not constructive : 0.24298160696999033\n",
      "too localized : 0.24193548387096775\n"
     ]
    }
   ],
   "source": [
    "plot_results(text_predicted_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.22212607892025807"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(predicted_y_test[(0 == np.round(predicted_y_test[:, 1]))][:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.60547104  0.39452896]\n",
      "10\n",
      "1384 324.0\n",
      "I 'm tearing my hair out . Apparently you ca n't just do something like I 've searched the internet and I ca n't find a simple example of how to implement the damn thing ANYWHERE . Even MSDN . It 's ridiculous .\n",
      "    class Ranch<T> : IEnumerable<T>\r",
      "     {\r",
      "        // Mad code\r",
      "         IEnumerator<T> GetEnumerator()\r",
      "         {\r",
      "             // Hectic implementation details\r",
      "         }\r",
      "        // More mad code\r",
      "     }\r\n",
      "[ 0.60547104  0.39452896]\n",
      "11\n",
      "3 2.0\n",
      "I searched a lot but could n't find the way to measure web page loading time with iOS . In the app , I want to show certain page loading time.. Is it possible with iOS sdk or third party sdk ? Thanks\n",
      "\n",
      "[ 0.60547104  0.39452896]\n",
      "12\n",
      "97 318.0\n",
      "I have downloaded 'Adobe Flash builder for Force.com ' from Salesforce site and trying to get some hands on . If any one has tried it before request you to please share your experience . Is there seom kind of good tutorial available that shows step by step procedure to create flex SFDC projects in eclipse ( Flas Builder 4 plugin versoin ) from scratch .\n",
      "\n",
      "[ 0.60547104  0.39452896]\n",
      "13\n",
      "1 48.9583333333\n",
      "Hey , So i have about 4-5 years of background in programming some in C # and some in C++ . I recently got an internship and have been using C # daily . I am confident in my work , and do n't have any problem remembering syntax or anything like that . So i was wondering what you guys think about getting reshaper ? i was going to demo it first but i just want to hear other opinions about it . Basically what I 'm trying to ask is , should i wait to get it and become more experienced and have more practice with just visual studios and its built in intellisense and stuff or would it be alright to get it ?\n",
      "\n",
      "[ 0.60547104  0.39452896]\n",
      "14\n",
      "744 396.0\n",
      "I 've been scouring the internet for a guide to creating an xbox application ( not a game ) but have been unsuccessful so far . I 've found that Microsoft provides XNA and XDK , and that the XDK is only available through their developer program . Is doesnt seem like it is possible to create an application by just using the XNA , however , I am not sure if this is correct or not . It does look like the XNA will allow you to create a game , but I 'm not sure if this is the right development kit to use if youre only creating an application . So , can I use the XNA to create an xbox application or do I need to do something else for this ? Thanks !\n",
      "\n",
      "[ 0.60547104  0.39452896]\n",
      "15\n",
      "1 0.0\n",
      "i am getting error like No fault address is defined for fault message can u help me < pre > & lt ; ds : direct bindOnElement= '' # document '' datasource= '' dbstore '' driver= '' com.mysql.jdbc.Driver '' url= '' jdbc : mysql : //localhost/mydb '' username= '' root '' password= '' root '' autoCommit= '' false '' / & gt ; & lt ; db : executor executeOnElement= '' /csv-set/csv-record '' datasource= '' dbstore '' executeBefore= '' true '' & gt ; & lt ; db : statement & gt ; INSERT INTO ctable VALUES ( $ { Customer.firstName ? string } , $ { Customer.lastName ? string } , $ { Customer.city ? string } , $ { Customer.country ? string } ) & lt ; /db : statement & gt ; & lt ; /db : executor & gt ; < /pre >\n",
      "\n",
      "[ 0.60547104  0.39452896]\n",
      "16\n",
      "854 244.0\n",
      "Very much new to this issue , need to fine total travelling distance while going from one location to another and also need to count total time spent to that travel.finding distance using latitude and longitude of two location do n't give correct result i think , because lat and lang distance gives us straight line distance even if we have lots of turning points etc ... while we are travelling . http : //stackoverflow.com/questions/3109158/how-to-draw-a-path-on-a-map-using-kml-file/3109723 # 3109723 i see this issue , good example has been given there i have implemented that also but it 's complicated bcs i do n't need to draw a routing path i just need to count total distance and total time . So Hoping for some one will helpme Thanks in advance Aamirkhan I .\n",
      "\n",
      "[ 0.60547104  0.39452896]\n",
      "17\n",
      "1 281.0\n",
      "Can anyone tell me on how to create 2 different project thro coding as Projectname_MIDP and Projectname_RIM like its created in lwuit1.5 GUI Builder automatically . Thanks\n",
      "\n",
      "[ 0.60547104  0.39452896]\n",
      "18\n",
      "462 6.04166666667\n",
      "We have always had languages that were preferable to be used in a particular scenario . For a quick prototype development , VB6 was an obvious choice . VB6 was chosen in projects that had a simple desktop user interface and standard and un-complicated database interaction requirements . If you wanted to develop a device driver using low-level routines , you probably relied on C or Visual C++ . ASP was a standard choice for development of web interfaces . Every language had a particular 'domain ' or 'specialization ' , speaking crudely . With .NET framework , all languages are interoperable and presumably consistent . You can have a project with modules from different languages all together but all ultimately being treated fairly similary ( all get compiled to IL ) . Does this mean that the distinction we had earlier no longer exists ? That differentiation was not necessarily bad rather something that was there by design and not due to any constraint . That apparently is diminshed somewhat with the .NET framework and its treatment of various languages . What is the experience of everyone , specially if you have worked in both managed and non-managed environments ?\n",
      "\n",
      "[ 0.60547104  0.39452896]\n",
      "19\n",
      "1381 27.0\n",
      "I have a system that combines the best and worst of Java and PHP . I am trying to migrate a component that was once written in PHP into a Java One . Does anyone have some tips for how I can parse a PHP serialized datastructure in Java ? By serialized I mean output from php 's serialize function .\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.4/lib/python3.4/site-packages/IPython/kernel/__main__.py:5: FutureWarning: in the future, boolean array-likes will be handled as a boolean array index\n"
     ]
    }
   ],
   "source": [
    "noquest = x_test[(y_test != np.round(predicted_y_test[:, 1])) & (x_test.Reason == 'not constructive')] \n",
    "# noquest = x_test[x_test.Reason == 'not a real question']\n",
    "noquest.index = range(len(noquest))\n",
    "for i in range(10, 20): \n",
    "    print((predicted_y_test[(y_test != np.round(predicted_y_test[:, 1])) & (x_test.Reason == 'not constructive')])[i])\n",
    "    print(i)\n",
    "    print(noquest.ReputationAtPostCreation[i], noquest.DaysBeforePost[i])\n",
    "    print(' '.join(noquest.Text[i]))\n",
    "    print(noquest.Code[i])\n",
    "# print(noquest.Questions_ratio.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count      707.000000\n",
       "mean       301.950495\n",
       "std        950.127468\n",
       "min          1.000000\n",
       "25%          1.000000\n",
       "50%         25.000000\n",
       "75%        179.500000\n",
       "max      13310.000000\n",
       "Name: ReputationAtPostCreation, dtype: float64"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noquest.ReputationAtPostCreation.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    100000.00000\n",
       "mean        512.30627\n",
       "std        2572.75879\n",
       "min         -34.00000\n",
       "25%           1.00000\n",
       "50%          36.00000\n",
       "75%         267.00000\n",
       "max      209631.00000\n",
       "Name: ReputationAtPostCreation, dtype: float64"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.ReputationAtPostCreation.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2281381090674411"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_test[(y_test != np.round(predicted_y_test[:, 1])) & \n",
    "           (x_test.Reason == 'not constructive')]) / len(x_test[x_test.Reason == 'not constructive'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.15392061955469508"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_test[(y_test != np.round(predicted_y_test[:, 1])) & (y_test != np.round(forest_prediction[:, 1]))&\n",
    "                 (x_test.Reason == 'not constructive')]) / len(x_test[x_test.Reason == 'not constructive'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2223297838012262"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_test[(y_test != np.round(new_predictor)) & \n",
    "           (x_test.Reason == 'not constructive')]) / len(x_test[x_test.Reason == 'not constructive'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 : 0.850614880441\n",
      "0.0263157894737 : 0.850614880441\n",
      "0.0526315789474 : 0.850614880441\n",
      "0.0789473684211 : 0.850614880441\n",
      "0.105263157895 : 0.850614880441\n",
      "0.131578947368 : 0.850614880441\n",
      "0.157894736842 : 0.850614880441\n",
      "0.184210526316 : 0.850614880441\n",
      "0.210526315789 : 0.850614880441\n",
      "0.236842105263 : 0.850614880441\n",
      "0.263157894737 : 0.850614880441\n",
      "0.289473684211 : 0.850614880441\n",
      "0.315789473684 : 0.850614880441\n",
      "0.342105263158 : 0.850614880441\n",
      "0.368421052632 : 0.850614880441\n",
      "0.394736842105 : 0.850614880441\n",
      "0.421052631579 : 0.850614880441\n",
      "0.447368421053 : 0.850614880441\n",
      "0.473684210526 : 0.850614880441\n",
      "0.5 : 0.850614880441\n"
     ]
    }
   ],
   "source": [
    "for threshold in np.linspace(0, 0.5, 20):\n",
    "    new_predictor = forest_prediction[:, 1]\n",
    "    new_predictor[np.abs(predicted_y_test[:, 1] - 0.5) > threshold] = \\\n",
    "        (predicted_y_test[:, 1])[np.abs(predicted_y_test[:, 1] - 0.5) > threshold]\n",
    "    print(threshold, \":\", roc_auc_score(y_test, new_predictor))\n",
    "# new_predictor = np.max((np.abs(predicted_y_test[:, 1] - 0.5), np.abs(forest_prediction[:, 1]- 0.5)),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.241075271487\n",
      "0.241075271487\n",
      "0.241075271487\n"
     ]
    }
   ],
   "source": [
    "i = 9090\n",
    "print(new_predictor[i])\n",
    "print(forest_prediction[i, 1])\n",
    "print(predicted_y_test[i, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Наводит на мысли. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Попробуем обучить отдельный классификатор по тексту"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cols = ['CodeLen', 'NumWords', 'NumSentences', 'Questions_ratio',  'NonWords', 'Digits', \n",
    "             'NonAlNums', 'EmptyTags', 'NumLastQuestions', 'Comma_ratio']\n",
    "cols_norm = cols\n",
    "cols_log = cols\n",
    "\n",
    "x_train_text = np.array(norm_scaler(x_tr[cols_norm[0]]))[:, None]\n",
    "x_test_text = np.array(norm_scaler(x_test[cols_norm[0]]))[:, None]\n",
    "for col in cols_norm[1:]:\n",
    "    x_train_text = np.hstack((x_train_text, np.array(norm_scaler(x_tr[col]))[:, None]))\n",
    "    x_test_text = np.hstack((x_test_text, np.array(norm_scaler(x_test[col]))[:, None]))\n",
    "for col in cols_log:\n",
    "    x_train_text = np.hstack((x_train_text, np.array(log_scaler(x_tr[col]))[:, None]))\n",
    "    x_test_text = np.hstack((x_test_text, np.array(log_scaler(x_test[col]))[:, None]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train_text = sps.csr_matrix(sps.hstack((x_train_2, tag_tr_tfidf, title_tr_tfidf, text_tr_tfidf, code_tr_tfidf, \n",
    "                                       small_bigrams_tr_tfidf, bititle_tr)))\n",
    "x_test_text = sps.csr_matrix(sps.hstack((x_test_2, tag_test_tfidf, title_test_tfidf, text_test_tfidf, code_test_tfidf, \n",
    "                                      small_bigrams_test_tfidf, bititle_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.849273605176\n"
     ]
    }
   ],
   "source": [
    "clf_linear = LogisticRegression()\n",
    "clf_linear.fit(x_train_text, y_tr)\n",
    "test_y_test = clf_linear.predict_proba(x_test_text)\n",
    "print(roc_auc_score(y_test, test_y_test[:, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for w in np.linspace(0, 1, 10):\n",
    "    print(roc_auc_score(y_test, w * text_y_test[:, 1] + (1 - w) * predicted_y_test[:, 1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Попробуем построить сложный алгоритм, который будет использовать результаты Random Forest и логистической регрессии"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попозже"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Попробуем выделить важные теги и слова в текстах и заголовках"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Функции для выделения словаря оптимальных слов и построения разреженной матрицы по данному словарю"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def choose_vocabulary(pos_df, neg_df, new_vocab_len):\n",
    "    word_fd = FreqDist()\n",
    "    label_word_fd = ConditionalFreqDist()\n",
    "    \n",
    "    for text in pos_df:\n",
    "        for word in text:\n",
    "            word_fd[word.lower()] += 1\n",
    "            label_word_fd['pos'][word.lower()] += 1\n",
    "    \n",
    "    for text in neg_df:\n",
    "        for word in text:\n",
    "            word_fd[word.lower()] += 1\n",
    "            label_word_fd['neg'][word.lower()] += 1\n",
    "    \n",
    "    pos_word_count = label_word_fd['pos'].N()\n",
    "    neg_word_count = label_word_fd['neg'].N()\n",
    "    total_word_count = pos_word_count + neg_word_count\n",
    "    \n",
    "    word_scores = {}\n",
    "    for word, freq in word_fd.items():\n",
    "        pos_score = BigramAssocMeasures.chi_sq(label_word_fd['pos'][word],\n",
    "            (freq, pos_word_count), total_word_count)\n",
    "        neg_score = BigramAssocMeasures.chi_sq(label_word_fd['neg'][word],\n",
    "            (freq, neg_word_count), total_word_count)\n",
    "        word_scores[word] = pos_score + neg_score\n",
    "    \n",
    "    best = sorted(word_scores.items(), key=operator.itemgetter(1))\n",
    "    bestwords = set([w for w, s in best[-new_vocab_len:]])\n",
    "    vocabulary = {}\n",
    "    for word in list(bestwords):\n",
    "        vocabulary.setdefault(word, len(vocabulary))\n",
    "    return vocabulary, best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def text_to_sparse_mat(df, vocabulary, shape=None):\n",
    "    indptr, indices, dt = [0], [], []\n",
    "    for text in df:\n",
    "        for word in text:\n",
    "            if word in vocabulary.keys():\n",
    "                index = vocabulary[word]\n",
    "                indices.append(index)\n",
    "                dt.append(1)\n",
    "        indptr.append(len(indices))\n",
    "    if shape is None:\n",
    "        mat = sps.csr_matrix((dt, indices, indptr), dtype=float)\n",
    "    else:\n",
    "        mat = sps.csr_matrix((dt, indices, indptr), dtype=float, shape=shape)\n",
    "    return mat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Теги"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vocabulary, best_words = choose_vocabulary(x_tr.Tags[y_tr == 1], x_tr.Tags[y_tr == 0], 500)\n",
    "tags_tr_mat = text_to_sparse_mat(x_tr.Tags, vocabulary)\n",
    "tags_test_mat = text_to_sparse_mat(x_test.Tags, vocabulary, shape=(len(y_test), len(vocabulary)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "transformer = TfidfTransformer()\n",
    "small_tag_tr_tfidf = transformer.fit_transform(tags_tr_mat)\n",
    "small_tag_test_tfidf = transformer.fit_transform(tags_test_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('interview-questions', 314.0751636471195),\n",
       " ('algorithm', 326.90989417952403),\n",
       " ('java', 353.92960766514267),\n",
       " ('career-development', 379.6728284041657),\n",
       " ('c', 390.37672085176735),\n",
       " ('ubuntu', 420.09236241492135),\n",
       " ('programming-languages', 442.9992701820673),\n",
       " ('linux', 655.0426960173544),\n",
       " ('books', 824.445753199567),\n",
       " ('php', 1089.6837563029196)]"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_words[-10:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Стемминг и очистка текста"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stop_words = stopwords.words('english') + ['this', 'doesn\\'t', 'would', 'could', 'don\\'t', 'im']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data['StemmedText'] = data.PureText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stemmer = nltk.stem.porter.PorterStemmer()\n",
    "data.PureText = data.PureText.apply(lambda text: [stemmer.stem(word) for word in text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data = data[:70000]\n",
    "test_data = data[70000:]\n",
    "train_columns = [col for col in data.columns if col != 'OpenStatus' and col != 'PostClosedDate']\n",
    "x_tr = train_data[train_columns]\n",
    "y_tr = train_data.OpenStatus\n",
    "x_test = test_data[train_columns]\n",
    "y_test = test_data.OpenStatus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vocabulary, best_words = choose_vocabulary(x_tr.StemmedText[y_tr == 1], x_tr.StemmedText[y_tr == 0], 1000)\n",
    "text_tr_mat = text_to_sparse_mat(x_tr.StemmedText, vocabulary)\n",
    "text_test_mat = text_to_sparse_mat(x_test.StemmedText, vocabulary, shape=(len(y_test), len(vocabulary)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "transformer = TfidfTransformer()\n",
    "small_text_tr_tfidf = transformer.fit_transform(text_tr_mat)\n",
    "small_text_test_tfidf = transformer.fit_transform(text_test_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('java', 2222.123327785344),\n",
       " ('me', 2304.4035165418104),\n",
       " ('good', 2572.877843878534),\n",
       " ('book', 2830.589559029197),\n",
       " ('languag', 3275.8731603279043),\n",
       " ('you', 3421.8325956676185),\n",
       " ('program', 3454.8842428873977),\n",
       " ('learn', 4147.922819978187),\n",
       " ('develop', 4511.108451246573),\n",
       " ('the', 12125.870559098008)]"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_words[-10:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vocabulary, best_words = choose_vocabulary(x_tr.Title[y_tr == 1], x_tr.Title[y_tr == 0], 1000)\n",
    "title_tr_mat = text_to_sparse_mat(x_tr.Title, vocabulary)\n",
    "title_test_mat = text_to_sparse_mat(x_test.Title, vocabulary, shape=(len(y_test), len(vocabulary)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('java', 439.2368387545045),\n",
       " ('website', 444.67590741344395),\n",
       " ('learning', 449.3334246997803),\n",
       " ('you', 451.3187663132005),\n",
       " ('code', 473.77039880059004),\n",
       " ('which', 480.15194838052946),\n",
       " ('development', 504.7113641507135),\n",
       " ('book', 511.2794781094807),\n",
       " ('php', 519.4437862586891),\n",
       " ('language', 529.4914582018488),\n",
       " ('learn', 535.9997967718931),\n",
       " ('software', 604.9853749943705),\n",
       " ('books', 714.4920847253122),\n",
       " ('good', 774.8362294555498),\n",
       " (':', 780.0319335366202),\n",
       " ('for', 808.1749242749489),\n",
       " ('?', 908.4750776240634),\n",
       " ('best', 1041.257102693981),\n",
       " ('programming', 1106.022668371447),\n",
       " ('what', 1726.5704046452045)]"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_words[-20:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "transformer = TfidfTransformer()\n",
    "small_title_tr_tfidf = transformer.fit_transform(title_tr_mat)\n",
    "small_title_test_tfidf = transformer.fit_transform(title_test_mat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vocabulary, best_words = choose_vocabulary(x_tr.SplittedCode[y_tr == 1], x_tr.SplittedCode[y_tr == 0], 500)\n",
    "code_tr_mat = text_to_sparse_mat(x_tr.SplittedCode, vocabulary)\n",
    "code_test_mat = text_to_sparse_mat(x_test.SplittedCode, vocabulary, shape=(len(y_test), len(vocabulary)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "transformer = TfidfTransformer()\n",
    "small_code_tr_tfidf = transformer.fit_transform(code_tr_mat)\n",
    "small_code_test_tfidf = transformer.fit_transform(code_test_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('boxman', 747.8743130910759),\n",
       " ('idx', 776.4194394154746),\n",
       " ('workspaceindex', 786.5616544163311),\n",
       " ('xmm', 788.8099783522462),\n",
       " ('debug', 802.3319799826629),\n",
       " ('class', 810.5540618676066),\n",
       " ('modules', 820.7817524321819),\n",
       " ('vs', 878.7584335924881),\n",
       " ('lt', 895.9131038475962),\n",
       " ('cout', 901.3908676572921),\n",
       " ('int', 977.7950895646475),\n",
       " ('q', 1002.8959898074042),\n",
       " ('option', 1115.8142364632117),\n",
       " ('self', 1122.9739526132153),\n",
       " ('if', 1161.5437299044045),\n",
       " ('field', 1243.0812518767098),\n",
       " ('id', 1705.856240961436),\n",
       " ('n', 1838.6451171125552),\n",
       " ('j', 1839.0213296812312),\n",
       " ('i', 3426.584959334477)]"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_words[-20:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def choose_bigram_vocabulary(pos_df, neg_df, new_vocab_len):\n",
    "    word_fd = FreqDist()\n",
    "    label_word_fd = ConditionalFreqDist()\n",
    "    \n",
    "    for text in pos_df:\n",
    "        bigrams_lst = list(nltk.bigrams(text))\n",
    "        for bigram in bigrams_lst:\n",
    "            word_fd[bigram] += 1\n",
    "            label_word_fd['pos'][bigram] += 1\n",
    "    \n",
    "    for text in neg_df:\n",
    "        bigrams_lst = list(nltk.bigrams(text))\n",
    "        for bigram in bigrams_lst:\n",
    "            word_fd[bigram] += 1\n",
    "            label_word_fd['neg'][bigram] += 1\n",
    "    \n",
    "    pos_word_count = label_word_fd['pos'].N()\n",
    "    neg_word_count = label_word_fd['neg'].N()\n",
    "    total_word_count = pos_word_count + neg_word_count\n",
    "    \n",
    "    word_scores = {}\n",
    "    for word, freq in word_fd.items():\n",
    "        pos_score = BigramAssocMeasures.chi_sq(label_word_fd['pos'][word],\n",
    "            (freq, pos_word_count), total_word_count)\n",
    "        neg_score = BigramAssocMeasures.chi_sq(label_word_fd['neg'][word],\n",
    "            (freq, neg_word_count), total_word_count)\n",
    "        word_scores[word] = pos_score + neg_score\n",
    "    \n",
    "    best = sorted(word_scores.items(), key=operator.itemgetter(1))\n",
    "#     print(best[-100:])\n",
    "#     for elem in best[-100:]:\n",
    "#         word = elem[0]\n",
    "#         print(elem[0])\n",
    "#         print('Positive:', label_word_fd['pos'][word])\n",
    "#         print('Negative:', label_word_fd['neg'][word])\n",
    "    bestwords = set([w for w, s in best[-new_vocab_len:]])\n",
    "    vocabulary = {}\n",
    "    for word in list(bestwords):\n",
    "        vocabulary.setdefault(word, len(vocabulary))\n",
    "    return vocabulary, list(best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def text_to_sparse_mat_bigrams(df, vocabulary, shape=None):\n",
    "    indptr, indices, dt = [0], [], []\n",
    "    for text in df:\n",
    "        bigrams_lst = list(nltk.bigrams(text))\n",
    "        for bigram in bigrams_lst:\n",
    "            if bigram in vocabulary.keys():\n",
    "                index = vocabulary[bigram]\n",
    "                indices.append(index)\n",
    "                dt.append(1)\n",
    "        indptr.append(len(indices))\n",
    "    if shape is None:\n",
    "        mat = sps.csr_matrix((dt, indices, indptr), dtype=float)\n",
    "    else:\n",
    "        mat = sps.csr_matrix((dt, indices, indptr), dtype=float, shape=shape)\n",
    "    return mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vocabulary, best_words = choose_bigram_vocabulary(x_tr.PureText[y_tr == 1], x_tr.PureText[y_tr == 0], 1000)\n",
    "bigrams_tr_mat = text_to_sparse_mat_bigrams(x_tr.PureText, vocabulary, shape=(len(y_tr), len(vocabulary)))\n",
    "bigrams_test_mat = text_to_sparse_mat_bigrams(x_test.PureText, vocabulary, shape=(len(y_test), len(vocabulary)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "transformer = TfidfTransformer()\n",
    "small_bigrams_tr_tfidf = transformer.fit_transform(bigrams_tr_mat)\n",
    "small_bigrams_test_tfidf = transformer.fit_transform(bigrams_test_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('the', 'dictionary'), 69.49041464069393),\n",
       " (('the', 'browser'), 69.52309008089568),\n",
       " (('who', 'is'), 69.55732708391982),\n",
       " (('I', 'writing'), 69.61122035342913),\n",
       " (('the', 'repository'), 69.63022579745427),\n",
       " (('to', 'query'), 69.88553813315752),\n",
       " (('should', 'learn'), 69.93470085470358),\n",
       " (('learn', 'C'), 69.93470085470358),\n",
       " (('Any', 'help'), 69.94191527099798),\n",
       " (('the', 'custom'), 69.98155996058946),\n",
       " (('ajax', 'call'), 70.04002988260294),\n",
       " (('know', 'of'), 70.04595430356127),\n",
       " (('the', 'label'), 70.11201347065148),\n",
       " (('an', 'attribute'), 70.12441847633264),\n",
       " (('the', 'screen'), 70.32934743071465),\n",
       " (('app', 'for'), 70.34565158892647),\n",
       " (('an', 'IDE'), 70.46175588090502),\n",
       " (('an', 'ajax'), 70.48645652847995),\n",
       " (('this', 'object'), 70.48645652847995),\n",
       " (('event', 'I'), 70.51906015646328),\n",
       " (('the', 'advantages'), 70.62494262276083),\n",
       " (('select', 'the'), 70.62693831284417),\n",
       " (('which', 'contains'), 70.63849195711943),\n",
       " (('like', 'me'), 70.71781013802234),\n",
       " (('the', 'validation'), 70.73044175174797),\n",
       " (('i', 'should'), 70.75661588831956),\n",
       " (('I', 'started'), 70.80761527497212),\n",
       " (('language', 'should'), 70.87520368298031),\n",
       " (('last', 'years'), 70.87520368298031),\n",
       " (('some', 'of'), 70.92260886106105),\n",
       " (('social', 'network'), 71.0863696643191),\n",
       " (('years', 'and'), 71.09557425046549),\n",
       " (('with', 'an'), 71.17687803791421),\n",
       " (('my', 'company'), 71.22841145846711),\n",
       " (('this', 'behavior'), 71.26641714563915),\n",
       " (('have', 'good'), 71.27972906658056),\n",
       " (('pass', 'a'), 71.31721535992077),\n",
       " (('good', 'at'), 71.41953503625682),\n",
       " (('boost', 'char'), 71.44611653226606),\n",
       " (('tried', 'adding'), 71.51060761022677),\n",
       " (('user', 'is'), 71.53941537033805),\n",
       " (('the', 'rows'), 71.53949434328001),\n",
       " (('when', 'using'), 71.55969459868116),\n",
       " (('things', 'about'), 71.56658212138811),\n",
       " (('anybody', 'help'), 71.66902360938259),\n",
       " (('this', 'Is'), 71.6854517380925),\n",
       " (('having', 'is'), 71.71671087965278),\n",
       " (('website', 'that'), 71.73109188222192),\n",
       " (('virtual', 'machine'), 71.73756892309149),\n",
       " (('web', 'pages'), 71.73756892309149)]"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_words[-1000:-950]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<70000x200000 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 2876665 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "small_bigrams_tr_tfidf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Nonpure 1-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vocabulary, best_words = choose_vocabulary(x_tr.Text[y_tr == 1], x_tr.Text[y_tr == 0], 5000)\n",
    "text_tr_mat = text_to_sparse_mat(x_tr.Text, vocabulary)\n",
    "text_test_mat = text_to_sparse_mat(x_test.Text, vocabulary, shape=(len(y_test), len(vocabulary)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "transformer = TfidfTransformer()\n",
    "small_text_tr_tfidf = transformer.fit_transform(text_tr_mat)\n",
    "small_text_test_tfidf = transformer.fit_transform(text_test_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('books', 1462.850206555511),\n",
       " (':', 1490.1487464243346),\n",
       " ('php', 1590.1988654592546),\n",
       " ('method', 1610.6595750204729),\n",
       " ('for', 1728.1543094475685),\n",
       " ('when', 1876.0520847435466),\n",
       " ('please', 1888.2981386789754),\n",
       " ('about', 1947.4377722133913),\n",
       " ('software', 2070.724757923574),\n",
       " ('this', 2097.8032076389777),\n",
       " ('language', 2130.854985814294),\n",
       " ('java', 2181.0572161908244),\n",
       " ('me', 2230.1357531661906),\n",
       " ('.chr', 2257.6931456752004),\n",
       " ('learn', 2489.0656426422465),\n",
       " ('good', 2518.4861282018223),\n",
       " ('programming', 3249.8915994023428),\n",
       " ('you', 3326.8090454118355),\n",
       " ('`', 3355.5555988189917),\n",
       " ('the', 12623.372177001089)]"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_words[-20:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Nonpure text bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 681,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vocabulary, best_words = choose_bigram_vocabulary(x_tr.Text[y_tr == 1], x_tr.Text[y_tr == 0], 10000)\n",
    "bigrams_tr_mat = text_to_sparse_mat(x_tr.Text, vocabulary, shape=(len(y_tr), len(vocabulary)))\n",
    "bigrams_test_mat = text_to_sparse_mat(x_test.Text, vocabulary, shape=(len(y_test), len(vocabulary)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 682,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "transformer = TfidfTransformer()\n",
    "small_bigrams_tr_tfidf = transformer.fit_transform(bigrams_tr_mat)\n",
    "small_bigrams_test_tfidf = transformer.fit_transform(bigrams_test_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 683,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('a', 'way'), 793.1271749248762),\n",
       " (('help', 'me'), 852.4774748878591),\n",
       " (('have', 'a'), 852.7846641452204),\n",
       " (('trying', 'to'), 855.6013928668348),\n",
       " (('to', 'the'), 912.6264073186763),\n",
       " (('looking', 'for'), 928.4672539363041),\n",
       " (('like', 'this'), 939.4017176257694),\n",
       " ((':', 'I'), 996.7627375733846),\n",
       " (('I', 'get'), 1052.383029724372),\n",
       " ((',', \"''\"), 1054.2253180850128),\n",
       " ((')', '`'), 1067.4304354418412),\n",
       " (('way', 'to'), 1111.4876339020989),\n",
       " (('I', 'have'), 1170.2207655952197),\n",
       " (('\\\\', \"''\"), 1187.7056529571526),\n",
       " (('this', ':'), 1195.2651152235876),\n",
       " (('in', 'the'), 1201.5857565380602),\n",
       " (('the', 'following'), 1269.634177474195),\n",
       " (('to', 'learn'), 1672.0846783804823),\n",
       " ((')', '.chr'), 2262.9662823286635),\n",
       " (('.chr', '('), 2262.9662823286635)]"
      ]
     },
     "execution_count": 683,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_words[-20:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Части Речи"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 712,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vocabulary, best_words = choose_vocabulary(x_tr.PartsOfSpeach[y_tr == 1], x_tr.PartsOfSpeach[y_tr == 0], 100)\n",
    "pos_tr_mat = text_to_sparse_mat(x_tr.PartsOfSpeach, vocabulary, shape=(len(y_tr), len(vocabulary)))\n",
    "pos_test_mat = text_to_sparse_mat(x_test.PartsOfSpeach, vocabulary, shape=(len(y_test), len(vocabulary)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 713,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('md', 458.8694462115534),\n",
       " ('rbr', 469.6399491999696),\n",
       " ('jjr', 584.788319683434),\n",
       " ('cc', 586.5775317933153),\n",
       " ('jjs', 830.8957212127995),\n",
       " ('nnp', 944.1987442821198),\n",
       " ('jj', 1157.4073944038716),\n",
       " ('wp', 1164.7416171727941),\n",
       " ('vbz', 1284.2941144558347),\n",
       " ('dt', 9336.416040942027)]"
      ]
     },
     "execution_count": 713,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_words[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 715,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "transformer = TfidfTransformer()\n",
    "pos_tr_tfidf = transformer.fit_transform(pos_tr_mat)\n",
    "pos_test_tfidf = transformer.fit_transform(pos_test_mat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Пунктуация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'Punctuation'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-412-6370525db79a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mvocabulary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchoose_vocabulary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_tr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPunctuation\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my_tr\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_tr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPunctuation\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my_tr\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mpunct_tr_mat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtext_to_sparse_mat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_tr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPunctuation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvocabulary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_tr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocabulary\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mpunct_test_mat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtext_to_sparse_mat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPunctuation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvocabulary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocabulary\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.4/lib/python3.4/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   2148\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2149\u001b[0m             raise AttributeError(\"'%s' object has no attribute '%s'\" %\n\u001b[0;32m-> 2150\u001b[0;31m                                  (type(self).__name__, name))\n\u001b[0m\u001b[1;32m   2151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2152\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'Punctuation'"
     ]
    }
   ],
   "source": [
    "vocabulary = choose_vocabulary(x_tr.Punctuation[y_tr == 1], x_tr.Punctuation[y_tr == 0], 500)\n",
    "punct_tr_mat = text_to_sparse_mat(x_tr.Punctuation, vocabulary, shape=(len(y_tr), len(vocabulary)))\n",
    "punct_test_mat = text_to_sparse_mat(x_test.Punctuation, vocabulary, shape=(len(y_test), len(vocabulary)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-82-bd0c9bd790c8>, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-82-bd0c9bd790c8>\"\u001b[0;36m, line \u001b[0;32m3\u001b[0m\n\u001b[0;31m    punct _test_tfidf = transformer.fit_transform(text_test_mat)\u001b[0m\n\u001b[0m                    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "transformer = TfidfTransformer()\n",
    "punct_tr_tfidf = transformer.fit_transform(text_tr_mat)\n",
    "punct _test_tfidf = transformer.fit_transform(text_test_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'CountVectorizer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-101-92fe119df759>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbigram_vectorizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCountVectorizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mngram_range\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken_pattern\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mr'\\b\\w+\\b'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_df\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'CountVectorizer' is not defined"
     ]
    }
   ],
   "source": [
    "bigram_vectorizer = CountVectorizer(ngram_range=(1, 2), token_pattern=r'\\b\\w+\\b', min_df=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Отбираем слова в PureText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vocabulary = choose_vocabulary(x_tr.PureText[y_tr == 1], x_tr.PureText[y_tr == 0], 100000)\n",
    "text_tr_mat = text_to_sparse_mat(x_tr.PureText, vocabulary, shape=(len(y_tr), len(vocabulary)))\n",
    "text_test_mat = text_to_sparse_mat(x_test.PureText, vocabulary, shape=(len(y_test), len(vocabulary)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "transformer = TfidfTransformer()\n",
    "text_tr_tfidf = transformer.fit_transform(text_tr_mat)\n",
    "text_test_tfidf = transformer.fit_transform(text_test_mat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#А что если просто по тексту?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vocabulary = choose_vocabulary(x_tr.Text[y_tr == 1], x_tr.Text[y_tr == 0], 100000)\n",
    "text_tr_mat = text_to_sparse_mat(x_tr.Text, vocabulary, shape=(len(y_tr), len(vocabulary)))\n",
    "text_test_mat = text_to_sparse_mat(x_test.Text, vocabulary, shape=(len(y_test), len(vocabulary)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "transformer = TfidfTransformer()\n",
    "text_tr_tfidf = transformer.fit_transform(text_tr_mat)\n",
    "text_test_tfidf = transformer.fit_transform(text_test_mat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#Отбираем слова в Title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vocabulary = choose_vocabulary(x_tr.PureText[y_tr == 1], x_tr.PureText[y_tr == 0], 500)\n",
    "text_tr_mat = text_to_sparse_mat(x_tr.PureText, vocabulary, shape=(len(y_tr), len(vocabulary)))\n",
    "text_test_mat = text_to_sparse_mat(x_test.PureText, vocabulary, shape=(len(y_test), len(vocabulary)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        In My VB.NET web page I have this standard eve...\n",
       "1        I trying to install VS on D drive but when i c...\n",
       "2        My IT knowledge resides mainly in SW developme...\n",
       "3        I have a single-threaded Rails app running on ...\n",
       "4        im trying to show printscreen image in picture...\n",
       "5        How can I create a div with rounded corners an...\n",
       "6        If I wanted to display a loading page while so...\n",
       "7        I have an assignment to teach a team the subje...\n",
       "8        Lets say I have developed a desktop applicatio...\n",
       "9        Could you please develop an automated script f...\n",
       "10       I have a global variable called when a user cl...\n",
       "11       How to execute one or more commands and script...\n",
       "12       I got a problem with ASIHTTPRequest in my iOS ...\n",
       "13       I have a view that for some reason displays th...\n",
       "14       I been asked to see if we can monitor the heal...\n",
       "15       In normal js one can iterate the window object...\n",
       "16       How to move a triangle to a new location using...\n",
       "17       In below code GroupCollection2 Compare functio...\n",
       "18       Can anybody pls suggest me a tutorial to play ...\n",
       "19       I want to show a grid of photos and I would li...\n",
       "20       Is there appeared easy way to underline text i...\n",
       "21       Can you recommend for me a URL that I may view...\n",
       "22       How can i design a leader board for online puz...\n",
       "23       I have purchased a VPS hosting Installed java ...\n",
       "24       i begginer for java spring framework and how t...\n",
       "25       I am making a normal distribution calculator i...\n",
       "26       According to RFC The plus dollar and comma cha...\n",
       "27       The only and imo very inconvenient caveat of s...\n",
       "28       I have a slider that has a fade-in and fade-ou...\n",
       "29       I get the following error message when renderi...\n",
       "                               ...                        \n",
       "69970    In my current project two model and is one-to-...\n",
       "69971    i keep getting this ERROR column reference per...\n",
       "69972    I like to have a form with questions each havi...\n",
       "69973    I have recently created a web browser for wind...\n",
       "69974    Open VS as admin I create a solution add new C...\n",
       "69975    I a Ruby on Rails newbie I learning Rails in m...\n",
       "69976    What is considered practice** when executing q...\n",
       "69977    I would like to create a table using divs wher...\n",
       "69978    Azure has quite a few different services piece...\n",
       "69979    In the below code alert in the first line is r...\n",
       "69980    I have a application written in ASP.NET which ...\n",
       "69981    Moving from android to java me I have some lit...\n",
       "69982    I wonder how did google engineer make the fron...\n",
       "69983    I am totally new to javascript and I have a ve...\n",
       "69984    This is my query i need this datas between to ...\n",
       "69985    I seen ways of programming in PHP Object Orien...\n",
       "69986    I ca n't get this working for the life of me H...\n",
       "69987    I have noticed a lot of developer these day de...\n",
       "69988    In the GCD documentation it quite clear that t...\n",
       "69989    C I have developed an application that need to...\n",
       "69990    i have a class wich send uri to change page af...\n",
       "69991    I am puzzled I have a call with jQuery using t...\n",
       "69992    Since I am new to WPF I want to get expert adv...\n",
       "69993    I may have to contribute to a legacy system cl...\n",
       "69994    The title might be confusing as I not sure mys...\n",
       "69995    I writing an application that checks some data...\n",
       "69996    I have a string after changing the positions o...\n",
       "69997    As I remember on Windows all the gems get inst...\n",
       "69998    Asked in an interview.. Write a function to sm...\n",
       "69999    i am trying to make a function that uses map a...\n",
       "Name: PureText, dtype: object"
      ]
     },
     "execution_count": 483,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_tr.PureText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70000, 1090637)"
      ]
     },
     "execution_count": 490,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigrams_tr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30000, 1090637)"
      ]
     },
     "execution_count": 489,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigrams_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.19164913498331618"
      ]
     },
     "execution_count": 499,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(bigrams_test[0].toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
