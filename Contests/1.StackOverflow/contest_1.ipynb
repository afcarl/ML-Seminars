{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import re\n",
    "import scipy.sparse as sps\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, TfidfTransformer\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import operator\n",
    "from collections import OrderedDict\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.collocations import BigramCollocationFinder\n",
    "from nltk.metrics import BigramAssocMeasures\n",
    "from nltk.probability import FreqDist, ConditionalFreqDist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_path = 'train-contest.csv'\n",
    "data = pd.read_csv(train_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Попробуем добавить несколько статистик"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Информация о тексте"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разобьем BodyMarkdown на код и текст"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data['Code'] = data.BodyMarkdown.apply(lambda text: [line for line in text.split('\\n') if \n",
    "                                                     line.startswith('    ') or line.startswith('\\t')])\n",
    "data['Text'] = data.BodyMarkdown.apply(lambda text: [line for line in text.split('\\n') if not\n",
    "                                                     line.startswith('    ') and not line.startswith('\\t')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data.Text = data.Text.apply(lambda text: '\\n'.join(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посчитаем несколько статистик"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    49978.000000\n",
       "mean         0.237885\n",
       "std          0.662161\n",
       "min          0.000000\n",
       "25%          0.000000\n",
       "50%          0.000000\n",
       "75%          0.000000\n",
       "max         17.000000\n",
       "Name: URLs, dtype: float64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['NonWords'] = data.Text.apply(lambda text: len(re.findall('[A-Za-z\\d_]+[ \\.\\?\\,\\!]', text)))\n",
    "data['Digits'] = data.Text.apply(lambda text: len(re.findall('\\d+', text)))\n",
    "data['NonAlNums'] = data.Text.apply(lambda text: len(re.findall('[^\\w\\s]+', text)))\n",
    "data['URLs'] = data.Text.apply(lambda text: len(re.findall('https?://', text)))\n",
    "data[data.OpenStatus == 0].URLs.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Удалим из текста не слова"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data.Text = data.Text.apply(lambda text: re.sub('https?://\\S', \" \", text))\n",
    "data.Text = data.Text.apply(lambda text: re.sub('[\\r\\t\\n]+', \" \", text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data['Questions'] = data.Text.apply(lambda text: len(re.findall(\"\\?\", text)))\n",
    "data['Exclamations'] = data.Text.apply(lambda text: len(re.findall(\"\\!\", text)))\n",
    "data['Statements'] = data.Text.apply(lambda text: len(re.findall(\"\\.\", text)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data['Questions_ratio'] = data['Questions'] / data['NumWords']\n",
    "data['Exclamations_ratio'] = data['Exclamations'] / data['NumWords']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data['NonAlNums_ratio'] = data['NonWords'] / data['NumWords']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    49970.000000\n",
       "mean         0.169964\n",
       "std          0.027376\n",
       "min          0.000000\n",
       "25%          0.159091\n",
       "50%          0.173913\n",
       "75%          0.186528\n",
       "max          0.320388\n",
       "Name: NonAlNums_ratio, dtype: float64"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[data.OpenStatus == 1].NonAlNums_ratio.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    49960.000000\n",
       "mean         0.167898\n",
       "std          0.024232\n",
       "min          0.000000\n",
       "25%          0.156463\n",
       "50%          0.171285\n",
       "75%          0.183246\n",
       "max          0.400000\n",
       "Name: NonAlNums_ratio, dtype: float64"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[data.OpenStatus == 0].NonAlNums_ratio.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# data.Text = data.Text.apply(lambda text: re.sub(\"[^\\w]\", \" \", text))\n",
    "data.Text = data.Text.apply(lambda text: re.sub(\"\\. \",\" . \", text))\n",
    "data.Text = data.Text.apply(lambda text: re.sub(\"[\\,\\!\\?] \",\"  \", text))\n",
    "data.Text = data.Text.apply(lambda text: re.sub(\" \",\"  \", text))\n",
    "# data.Text = data.Text.apply(lambda text: \"  \".join(text.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data.Text = data.Text.apply(lambda text: re.findall(' [A-Za-z][a-z]* ', text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Число предложений в тексте"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data['NumSentences'] = data.Text.apply(lambda text: len(nltk.sent_tokenize(\" \".join(text))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Стеммим слова"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data.Text = data.Text.apply(lambda text: [word.lower() for word in text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stemmer = nltk.stem.porter.PorterStemmer()\n",
    "data.Text = data.Text.apply(lambda text: [stemmer.stem(word) for word in text])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Длина текста в символах"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data['NumWords'] = data.Text.apply(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Длина кода в символах"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data['CodeLen'] = data['Code'].apply(lambda x: len(\"\".join(x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Стэммим заголовки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data.Title = data.Title.apply(lambda text: re.sub(\"[^a-z0-9\\^$#@*+/\\-=]\", \" \", text.lower()).split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stemmer = nltk.stem.porter.PorterStemmer()\n",
    "data.Title = data.Title.apply(lambda text: [stemmer.stem(word) for word in text])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Информация о пользователе"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.4/lib/python3.4/site-packages/pandas/core/generic.py:2177: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self[name] = value\n"
     ]
    }
   ],
   "source": [
    "data['PostCreationDate'] = data['PostCreationDate'].apply(lambda x: time.strptime(x[:10], \"%m/%d/%Y\"))\n",
    "data['OwnerCreationDate'] = data['OwnerCreationDate'].apply(lambda x: x if (x != '2008-09-01') else '01/09/2008')\n",
    "data['OwnerCreationDate'] = data['OwnerCreationDate'].apply(lambda x: time.strptime(x[:10], \"%m/%d/%Y\"))\n",
    "data['OwnerCreationDate'] = data['OwnerCreationDate'].apply(lambda x: time.mktime(x) / 86400)\n",
    "data['PostCreationDate'] = data['PostCreationDate'].apply(lambda x: time.mktime(x) / 86400)\n",
    "data['DaysBeforePost'] = data['PostCreationDate'] - data['OwnerCreationDate']\n",
    "data[data['DaysBeforePost'] < 0].DaysBeforePost = -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Теги"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data['Tags'] = list(zip(data.Tag1.fillna(\"\"), \n",
    "                               data.Tag2.fillna(\"\"), data.Tag3.fillna(\"\"), \n",
    "                               data.Tag4.fillna(\"\"), data.Tag5.fillna(\"\"))) \n",
    "data['Tags'] = data['Tags'].apply(lambda x: (\" \".join(x).lower().split()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Тестовая и обучающая выборки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data = data[:70000]\n",
    "test_data = data[70000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_columns = [col for col in data.columns if col != 'OpenStatus' and col != 'PostClosedDate']\n",
    "x_tr = train_data[train_columns]\n",
    "y_tr = train_data.OpenStatus\n",
    "x_test = test_data[train_columns]\n",
    "y_test = test_data.OpenStatus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Посчитаем tf-idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'In My VB.NET web page, I have this standard event. Note the \"Handles\" clause on teh event declaration. In my C# web app, I have this: Since C# doesn\\'t have a \"Handles\" equivalent and from what I\\'ve seen, event handlers are wired up using delegate += syntax, I was looking for this, but I could not foind it in the aspx page, aspx.cs file or the aspx.designer.cs file. In VB, I would have two drop down lists at the top of  the Code Editor window and I could select any object on the web form or the web form itself and see the possible events for the object. Selecting the event would either take me to the event handler or if it didn\\'t exists, it would create the stub for me. I know that the Properties window in C# (and I think in VB, too) has an Event tab that shows the list of events for the selected object GUI object, but \"Page\" doesn\\'t appear as an object that can be selected. 1. Where does C# define the hooking up of the event to the handler?  2.  How do I generate a stub for the Page event handler routine? I know that the handle appears by default, but what if it is deleted or I want to add a Page_initialize code? Is there an easy way to get the stub or do I need to go to the Object Browser for the syntax? '"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.Text[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vect = TfidfVectorizer(min_df=1/len(x_tr), max_df=0.9, lowercase=False, tokenizer=lambda doc: doc)\n",
    "text_tr_tfidf = vect.fit_transform(x_tr.Text)\n",
    "text_test_tfidf = vect.transform(x_test.Text)\n",
    "title_tr_tfidf = vect.fit_transform(x_tr.Title)\n",
    "title_test_tfidf = vect.transform(x_test.Title)\n",
    "tag_tr_tfidf = vect.fit_transform(x_tr.Tags)\n",
    "tag_test_tfidf = vect.transform(x_test.Tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(70000, 13938)\n",
      "(70000, 234)\n",
      "(70000, 1351)\n"
     ]
    }
   ],
   "source": [
    "print(tag_tr_tfidf.shape)\n",
    "print(title_tr_tfidf.shape)\n",
    "print(text_tr_tfidf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def log_scaler(df):\n",
    "    new_df = df.copy()\n",
    "    if new_df.min() < 0:\n",
    "        new_df -= new_df.min()\n",
    "    new_df = np.log(new_df + 1)\n",
    "    return (new_df - new_df.mean())/ (new_df.max() - new_df.min())\n",
    "\n",
    "def norm_scaler(df):\n",
    "    new_df = df.copy()\n",
    "    return (new_df - new_df.mean())/ (new_df.max() - new_df.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cols_norm = ['CodeLen', 'NumSentences', 'NumWords', 'NonWords', 'Digits', 'NonAlNums']\n",
    "cols_log = ['DaysBeforePost', 'ReputationAtPostCreation', 'OwnerUndeletedAnswerCountAtPostTime']\n",
    "\n",
    "x_train_2 = np.array(norm_scaler(x_tr[cols_norm[1]]))[:, None]\n",
    "x_test_2 = np.array(norm_scaler(x_test[cols_norm[1]]))[:, None]\n",
    "for col in cols_norm[1:]:\n",
    "    x_train_2 = np.hstack((x_train_2, np.array(norm_scaler(x_tr[col]))[:, None]))\n",
    "    x_test_2 = np.hstack((x_test_2, np.array(norm_scaler(x_test[col]))[:, None]))\n",
    "for col in cols_log:\n",
    "    x_train_2 = np.hstack((x_train_2, np.array(norm_scaler(x_tr[col]))[:, None]))\n",
    "    x_test_2 = np.hstack((x_test_2, np.array(norm_scaler(x_test[col]))[:, None]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_train_2 = sps.csr_matrix(sps.hstack((x_train_2, tag_tr_tfidf)))#, title_tr_tfidf, tag_tr_tfidf)))\n",
    "x_test_2 = sps.csr_matrix(sps.hstack((x_test_2, tag_test_tfidf)))#, title_test_tfidf, tag_test_tfidf)))\n",
    "# x_train_2 = sps.csr_matrix(tag_tr_tfidf)\n",
    "# x_test_2 = sps.csr_matrix(tag_test_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.721352747637\n"
     ]
    }
   ],
   "source": [
    "clf_linear = LogisticRegression()\n",
    "clf_linear.fit(x_train_2, y_tr)\n",
    "predicted_y_test = clf_linear.predict_proba(x_test_2)\n",
    "print(roc_auc_score(y_test, predicted_y_test[:, 1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Отбор слов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word_fd = FreqDist()\n",
    "label_word_fd = ConditionalFreqDist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Частоты в положительных примерах"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for text in x_tr.Text[y_tr == 1]:\n",
    "    for word in text:\n",
    "        word_fd[word.lower()] += 1\n",
    "        label_word_fd['pos'][word.lower()] += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Частоты в отрицательных примерах"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for text in x_tr.Text[y_tr == 0]:\n",
    "    for word in text:\n",
    "        word_fd[word.lower()] += 1\n",
    "        label_word_fd['neg'][word.lower()] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pos_word_count = label_word_fd['pos'].N()\n",
    "neg_word_count = label_word_fd['neg'].N()\n",
    "total_word_count = pos_word_count + neg_word_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "word_scores = {}\n",
    "for word, freq in word_fd.items():\n",
    "    pos_score = BigramAssocMeasures.chi_sq(label_word_fd['pos'][word],\n",
    "        (freq, pos_word_count), total_word_count)\n",
    "    neg_score = BigramAssocMeasures.chi_sq(label_word_fd['neg'][word],\n",
    "        (freq, neg_word_count), total_word_count)\n",
    "    word_scores[word] = pos_score + neg_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "best = sorted(word_scores.items(), key=operator.itemgetter(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_fd['flux']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_word_fd['neg']['flux']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'int' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-111-c7b807116948>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtotal_word_count\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'flux'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: 'int' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "total_word_count['flux']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' switches ',\n",
       " ' central ',\n",
       " ' thros ',\n",
       " ' teenager ',\n",
       " ' process ',\n",
       " ' normalize ',\n",
       " ' madan ',\n",
       " ' liquid ',\n",
       " ' lunched ',\n",
       " ' flour ',\n",
       " ' acocunt ',\n",
       " ' consumption ',\n",
       " ' ted ',\n",
       " ' charaters ',\n",
       " ' deffinately ',\n",
       " ' wampserver ',\n",
       " ' linke ',\n",
       " ' recordsets ',\n",
       " ' inoperative ',\n",
       " ' admit ',\n",
       " ' hows ',\n",
       " ' dealt ',\n",
       " ' transcribed ',\n",
       " ' diplaying ',\n",
       " ' listfield ',\n",
       " ' colons ',\n",
       " ' opportunistic ',\n",
       " ' flashyness ',\n",
       " ' ferda ',\n",
       " ' tmp ',\n",
       " ' schemagen ',\n",
       " ' shiro ',\n",
       " ' boned ',\n",
       " ' shifting ',\n",
       " ' gemset ',\n",
       " ' greyed ',\n",
       " ' otherways ',\n",
       " ' fart ',\n",
       " ' fallows ',\n",
       " ' unveil ',\n",
       " ' frictionless ',\n",
       " ' databased ',\n",
       " ' intrigues ',\n",
       " ' authentificator ',\n",
       " ' modernizr ',\n",
       " ' unfortunatelly ',\n",
       " ' dolphin ',\n",
       " ' looked ',\n",
       " ' invalide ',\n",
       " ' hats ',\n",
       " ' ideallyin ',\n",
       " ' combos ',\n",
       " ' aplicattion ',\n",
       " ' curios ',\n",
       " ' flagging ',\n",
       " ' vase ',\n",
       " ' logarithmic ',\n",
       " ' vale ',\n",
       " ' blades ',\n",
       " ' sore ',\n",
       " ' terabytes ',\n",
       " ' din ',\n",
       " ' dups ',\n",
       " ' pie ',\n",
       " ' heallth ',\n",
       " ' xmldom ',\n",
       " ' modularity ',\n",
       " ' respnse ',\n",
       " ' boiler ',\n",
       " ' mitigate ',\n",
       " ' constness ',\n",
       " ' leaderboard ',\n",
       " ' foreman ',\n",
       " ' shirt ',\n",
       " ' perfectally ',\n",
       " ' reddish ',\n",
       " ' tocal ',\n",
       " ' recomendation ',\n",
       " ' popin ',\n",
       " ' prodid ',\n",
       " ' ll ',\n",
       " ' ourselfs ',\n",
       " ' vanishes ',\n",
       " ' intermittently ',\n",
       " ' realised ',\n",
       " ' piqued ',\n",
       " ' transitioned ',\n",
       " ' mongod ',\n",
       " ' deletions ',\n",
       " ' albeit ',\n",
       " ' stuck ',\n",
       " ' intersect ',\n",
       " ' opposed ',\n",
       " ' adsense ',\n",
       " ' crafty ',\n",
       " ' intriguing ',\n",
       " ' sorters ',\n",
       " ' severs ',\n",
       " ' apreciate ',\n",
       " ' dodge ']"
      ]
     },
     "execution_count": 483,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(bestwords)[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bestwords = set([w for w, s in best[:20000]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Формируем словарь"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vocabulary = {}\n",
    "for word in list(bestwords):\n",
    "    vocabulary.setdefault(word, len(vocabulary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20000"
      ]
     },
     "execution_count": 495,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "indptr, indices, dt = [0], [], []\n",
    "for article in x_tr.Text:\n",
    "    for word in article:\n",
    "        if word in vocabulary.keys():\n",
    "            index = vocabulary[word]\n",
    "            indices.append(index)\n",
    "            dt.append(1)\n",
    "    indptr.append(len(indices))\n",
    "text = sps.csr_matrix((dt, indices, indptr), dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "indptr, indices, dt = [0], [], []\n",
    "for article in x_test.Text:\n",
    "    for word in article:\n",
    "        if word in vocabulary.keys():\n",
    "            index = vocabulary[word]\n",
    "            indices.append(index)\n",
    "            dt.append(1)\n",
    "    indptr.append(len(indices))\n",
    "text_test = sps.csr_matrix((dt, indices, indptr), dtype=float, shape=(len(x_test.Text), text.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "transformer = TfidfTransformer()\n",
    "text_tfidf = transformer.fit_transform(text)\n",
    "text_test_tfidf = transformer.fit_transform(text_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "code = np.array(new_scaler(x_tr['CodeLen']))[:, None]\n",
    "code_test = np.array(new_scaler(x_test['CodeLen']))[:, None]\n",
    "# code_scaled = x_tr['CodeLen']\n",
    "# code_scaled[code_scaled > 0] = 1\n",
    "# code_test_scaled = x_tr['CodeLen']\n",
    "# code_test_scaled[code_scaled > 0] = 1\n",
    "num_sent = np.array(new_scaler(x_tr['NumSentences']))[:, None]\n",
    "num_sent_test = np.array(new_scaler(x_test['NumSentences']))[:, None]\n",
    "num_words = np.array(new_scaler(x_tr['NumWords']))[:, None]\n",
    "num_words_test = np.array(new_scaler(x_test['NumWords']))[:, None]\n",
    "days = np.array(new_scaler(x_tr['DaysBeforePost']))[:, None]\n",
    "days_test = np.array(new_scaler(x_test['DaysBeforePost']))[:, None]\n",
    "reputations = np.array(new_scaler(x_tr['ReputationAtPostCreation']))[:, None]\n",
    "reputations_test = np.array(new_scaler(x_test['ReputationAtPostCreation']))[:, None]\n",
    "answers = np.array(new_scaler(x_tr['OwnerUndeletedAnswerCountAtPostTime']))[:, None]\n",
    "answers_test = np.array(new_scaler(x_test['OwnerUndeletedAnswerCountAtPostTime']))[:, None]\n",
    "\n",
    "x_train_2 = np.hstack((code, num_sent, num_words, days, reputations, answers))\n",
    "x_test_2 = np.hstack((code_test, num_sent_test, num_words_test, days_test, reputations_test, answers_test))\n",
    "x_train_2 = sps.csr_matrix(sps.hstack((x_train_2, text_tfidf)))\n",
    "x_test_2 = sps.csr_matrix(sps.hstack((x_test_2, text_test_tfidf)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70000, 20006)"
      ]
     },
     "execution_count": 500,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.720487606391\n"
     ]
    }
   ],
   "source": [
    "clf_linear = LogisticRegression()\n",
    "clf_linear.fit(x_train_2, y_tr)\n",
    "predicted_y_test = clf_linear.predict_proba(x_test_2)\n",
    "print(roc_auc_score(y_test, predicted_y_test[:, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
