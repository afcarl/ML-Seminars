{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Контест 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Baseline\n",
    "###Предобработка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import xgboost as xgb\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features = pandas.read_csv('data/features.csv', index_col='match_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "matches = features.copy()\n",
    "del matches['duration']\n",
    "del matches['radiant_win']\n",
    "del matches['tower_status_dire']\n",
    "del matches['tower_status_radiant']\n",
    "del matches['barracks_status_radiant']\n",
    "del matches['barracks_status_dire']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "matches = matches.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "categorical_columns = ['lobby_type']\n",
    "for i in range(1, 6):\n",
    "    categorical_columns.append('r'+str(i)+'_hero')\n",
    "    categorical_columns.append('r'+str(i)+'_hero')\n",
    "other_cols = [col for col in matches.columns if not (col in categorical_columns)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "transformer = DictVectorizer(sparse=False)\n",
    "matches_arr = transformer.fit_transform(matches[categorical_columns].astype(str).T.to_dict().values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train = np.hstack((matches_arr, matches[other_cols]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_size = 70000\n",
    "test = train[train_size:, :]\n",
    "train = train[:train_size, :]\n",
    "y_train = np.array(features['radiant_win'])\n",
    "y_test = y_train[train_size:]\n",
    "y_train = y_train[:train_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocess(data, cat_cols, other_cols, train_size=None):\n",
    "    if train_size is None:\n",
    "        train_size = int(2 * data.shape[0] / 3)\n",
    "    y_train = np.array(data['radiant_win'])\n",
    "    y_test = y_train[train_size:]\n",
    "    y_train = y_train[:train_size]\n",
    "    del data['duration']\n",
    "    del data['radiant_win']\n",
    "    del data['tower_status_dire']\n",
    "    del data['tower_status_radiant']\n",
    "    del data['barracks_status_radiant']\n",
    "    del data['barracks_status_dire']\n",
    "    transformer = DictVectorizer(sparse=False)\n",
    "    data_arr = transformer.fit_transform(data[cat_cols].astype(str).T.to_dict().values())\n",
    "    data = np.hstack((data_arr, data[other_cols]))\n",
    "    test = data[train_size:, :]\n",
    "    train = data[:train_size, :]\n",
    "    return train, y_train, test, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-2f756ed15ffd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdtrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDMatrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDMatrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train' is not defined"
     ]
    }
   ],
   "source": [
    "dtrain = xgb.DMatrix(train, label=y_train)\n",
    "dtest = xgb.DMatrix(test, label=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dtest' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-b364447b15b3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mparam\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'nthread'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mparam\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'eval_metric'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'auc'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mevallist\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'eval'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'dtest' is not defined"
     ]
    }
   ],
   "source": [
    "param = {'bst:max_depth':2, 'bst:eta':1, 'silent':1, 'objective':'binary:logistic' }\n",
    "param['nthread'] = 4\n",
    "param['eval_metric'] = 'auc'\n",
    "evallist  = [(dtest,'eval'), (dtrain,'train')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "num_round = 10\n",
    "bst = xgb.train(param, dtrain, num_round)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_pred = bst.predict(dtest,ntree_limit=bst.best_ntree_limit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.68126207054796417"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Эксперименты"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Тип Лобби"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    55962\n",
       "7    28550\n",
       "0    12718\n",
       "dtype: int64"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features['lobby_type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "features_1 = features[features['lobby_type'] != 7]\n",
    "features_1 = features_1.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train, y_train, test, y_test = preprocess(features_1, categorical_columns, other_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dtrain = xgb.DMatrix(train, label=y_train)\n",
    "dtest = xgb.DMatrix(test, label=y_test)\n",
    "param = {'bst:max_depth':3, 'bst:eta':1, 'silent':1, 'objective':'binary:logistic' }\n",
    "param['nthread'] = 4\n",
    "param['eval_metric'] = 'auc'\n",
    "evallist  = [(dtest,'eval'), (dtrain,'train')]\n",
    "num_round = 10\n",
    "bst = xgb.train(param, dtrain, num_round)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.67780254453946687"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = bst.predict(dtest,ntree_limit=bst.best_ntree_limit)\n",
    "roc_auc_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На типе лобби 7 плохое качество"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Удалим лишние признаки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "categorical_columns = ['lobby_type']\n",
    "for i in range(1, 6):\n",
    "    categorical_columns.append('r'+str(i)+'_hero')\n",
    "    categorical_columns.append('r'+str(i)+'_hero')\n",
    "other_cols = [col for col in matches.columns if not (col in categorical_columns)\n",
    "              and col != 'start_time' and 'col != lobby_type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train, y_train, test, y_test = preprocess(features_1.fillna(0), categorical_columns, other_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dtrain = xgb.DMatrix(train, label=y_train)\n",
    "dtest = xgb.DMatrix(test, label=y_test)\n",
    "param = {'bst:max_depth':3, 'bst:eta':1, 'silent':1, 'objective':'binary:logistic' }\n",
    "param['nthread'] = 4\n",
    "param['eval_metric'] = 'auc'\n",
    "evallist  = [(dtest,'eval'), (dtrain,'train')]\n",
    "num_round = 10\n",
    "bst = xgb.train(param, dtrain, num_round)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.68929945323680353"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = bst.predict(dtest,ntree_limit=bst.best_ntree_limit)\n",
    "roc_auc_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Герои"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "heroes = []\n",
    "for i in range(1, 6):\n",
    "    heroes += list(features['r'+str(i)+'_hero'].values)\n",
    "    heroes += list(features['r'+str(i)+'_hero'].values)\n",
    "heroes = list(set(heroes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####Простая сумма характеристик"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "matches = features.copy()\n",
    "matches = matches.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fields = ['level', 'gold', 'xp', 'lh', 'kills', 'deaths', 'items']\n",
    "teams = ['r', 'd']\n",
    "players = range(1, 6)\n",
    "for field in fields:\n",
    "    for team in teams:\n",
    "        name = team + '_' + field\n",
    "        matches[name] = 0\n",
    "        for player in players:\n",
    "            matches[name] += matches[team + str(player) + '_' + field] \n",
    "            del matches[team + str(player) + '_' + field] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bad_columns = ['duration', 'radiant_win', 'tower_status_dire', 'tower_status_radiant','barracks_status_radiant',\n",
    "               'barracks_status_dire']\n",
    "categorical_columns = ['lobby_type']\n",
    "for i in range(1, 6):\n",
    "    categorical_columns.append('r'+str(i)+'_hero')\n",
    "    categorical_columns.append('d'+str(i)+'_hero')\n",
    "other_cols = [col for col in matches.columns if not (col in categorical_columns)\n",
    "             and not (col in bad_columns)]\n",
    "#               and col != 'start_time']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train, y_train, test, y_test = preprocess(matches, categorical_columns, other_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dtrain = xgb.DMatrix(train, label=y_train)\n",
    "dtest = xgb.DMatrix(test, label=y_test)\n",
    "param = {'bst:max_depth':3, 'bst:eta':1, 'silent':1, 'objective':'binary:logistic' }\n",
    "param['nthread'] = 4\n",
    "param['eval_metric'] = 'auc'\n",
    "evallist  = [(dtest,'eval'), (dtrain,'train')]\n",
    "num_round = 10\n",
    "bst = xgb.train(param, dtrain, num_round)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.70705343471168769"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = bst.predict(dtest,ntree_limit=bst.best_ntree_limit)\n",
    "roc_auc_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####Взвешенная сумма характеристик\n",
    "Попробуем для каждого героя посчитать корреляцию его показателей с результатом"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "matches = features.copy()\n",
    "matches = matches.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fields = ['hero', 'level', 'gold', 'xp', 'lh', 'kills', 'deaths', 'items']\n",
    "teams = ['r', 'd']\n",
    "players = range(1, 6)\n",
    "field_lst = []\n",
    "for field in fields:\n",
    "    for team in teams:\n",
    "        for player in players:\n",
    "            field_lst.append(team+str(player)+'_'+field)\n",
    "field_lst += ['radiant_win', 'duration', 'tower_status_radiant', 'tower_status_dire', \n",
    "              'barracks_status_radiant', 'barracks_status_dire']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "matches = matches[field_lst]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "matches_hero = pandas.concat([matches[matches['r1_hero'] == 1]] + [matches[matches['r2_hero'] == 1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.4/lib/python3.4/site-packages/IPython/kernel/__main__.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Library/Frameworks/Python.framework/Versions/3.4/lib/python3.4/site-packages/pandas/core/frame.py:2148: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self[k1] = value[k2]\n"
     ]
    }
   ],
   "source": [
    "hero = 93\n",
    "bad_columns = ['radiant_win']\n",
    "fields = ['level', 'gold', 'xp', 'lh', 'kills', 'deaths', 'items']\n",
    "teams = ['r', 'd']\n",
    "players = range(1, 6)\n",
    "frames = []\n",
    "for team in teams:\n",
    "    for player in players:\n",
    "        frame = matches[matches[team + str(player) + '_hero'] == hero]\n",
    "        for field in fields:\n",
    "            player_field = team + str(player) + '_' + field\n",
    "            frame[field] = frame[player_field]\n",
    "        if team == 'd':\n",
    "            frame[bad_columns] = frame[bad_columns] * (-1) + 1\n",
    "        frames.append(frame[fields + bad_columns])\n",
    "    \n",
    "matches_hero = pandas.concat(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1441.8954028925621"
      ]
     },
     "execution_count": 352,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matches_hero[matches_hero['radiant_win'] == 1].gold.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "matches_arr = np.array(matches_hero)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "matches_arr = scaler.fit_transform(matches_arr.astype(float))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10783, 7)"
      ]
     },
     "execution_count": 337,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matches_arr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_size = int(matches_arr.shape[0] * 2 /3)\n",
    "train = matches_arr[:train_size, :]\n",
    "test = matches_arr[train_size:, :]\n",
    "y_train = matches_hero['radiant_win']\n",
    "y_test = y_train[train_size:]\n",
    "y_train = y_train[:train_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dtrain = xgb.DMatrix(train, label=y_train)\n",
    "dtest = xgb.DMatrix(test, label=y_test)\n",
    "param = {'bst:max_depth':3, 'bst:eta':1, 'silent':1, 'objective':'binary:logistic' }\n",
    "param['nthread'] = 4\n",
    "param['eval_metric'] = 'auc'\n",
    "evallist  = [(dtest,'eval'), (dtrain,'train')]\n",
    "num_round = 10\n",
    "bst = xgb.train(param, dtrain, num_round)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.58706529579066413"
      ]
     },
     "execution_count": 340,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = bst.predict(dtest,ntree_limit=bst.best_ntree_limit)\n",
    "roc_auc_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(train, y_train)\n",
    "y_pred = logreg.predict_proba(test)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.61268619982893024"
      ]
     },
     "execution_count": 342,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####Выбранные герои"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "matches = features.copy()\n",
    "matches = matches.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hero_fields = ['r'+str(i)+'_hero' for i in range(1, 6)] + ['d'+str(i)+'_hero' for i in range(1, 6)]\n",
    "matches_hero = matches[hero_fields + ['radiant_win']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "N = 113\n",
    "data = matches\n",
    "X_pick = np.zeros((data.shape[0], N))\n",
    "for i, match_id in enumerate(data.index):\n",
    "    for p in range(5):\n",
    "        X_pick[i, data.ix[match_id, 'r%d_hero' % (p+1)]-1] = 1\n",
    "        X_pick[i, data.ix[match_id, 'd%d_hero' % (p+1)]-1] = -1\n",
    "for i, match_id in enumerate(data.index):\n",
    "    for p in range(5):\n",
    "        X_pick[i, data.ix[match_id, 'r%d_hero' % (p+1)]-1] = 1\n",
    "        X_pick[i, data.ix[match_id, 'd%d_hero' % (p+1)]-1] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_size = int(matches.shape[0] * 2 / 3)\n",
    "train = X_pick[:train_size, :]\n",
    "test = X_pick[train_size:, :]\n",
    "y_train = matches['radiant_win']\n",
    "y_test = y_train[train_size:]\n",
    "y_train = y_train[:train_size]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Логистическая Регрессия"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.60137657794217358"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg = LogisticRegression()\n",
    "logreg.fit(train, y_train)\n",
    "logreg_preds = logreg.predict_proba(test)[:, 1]\n",
    "roc_auc_score(y_test, logreg_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_logreg_preds = logreg.predict_proba(train)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "full_logreg_preds = np.hstack((train_logreg_preds, logreg_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Бустинг"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dtrain = xgb.DMatrix(train, label=y_train)\n",
    "dtest = xgb.DMatrix(test, label=y_test)\n",
    "param = {'bst:max_depth':3, 'bst:eta':1, 'silent':1, 'objective':'binary:logistic' }\n",
    "param['nthread'] = 4\n",
    "param['eval_metric'] = 'auc'\n",
    "evallist  = [(dtest,'eval'), (dtrain,'train')]\n",
    "num_round = 10\n",
    "bst = xgb.train(param, dtrain, num_round)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.56676921118967205"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boost_preds = bst.predict(dtest,ntree_limit=bst.best_ntree_limit)\n",
    "roc_auc_score(y_test, boost_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Случайный Лес"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.57763439374103887"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest = RandomForestClassifier(n_estimators=100)\n",
    "forest.fit(train, y_train)\n",
    "forest_preds = forest.predict_proba(test)[:, 1]\n",
    "roc_auc_score(y_test, forest_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "svm = SVC()\n",
    "svm.fit(train, y_train)\n",
    "svm_preds = svm.predict_proba(test)[:, 1]\n",
    "roc_auc_score(y_test, forest_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####Нейронная сеть"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pybrain.datasets import SupervisedDataSet\n",
    "from pybrain.utilities import percentError\n",
    "from pybrain.tools.shortcuts import buildNetwork\n",
    "from pybrain.supervised.trainers import BackpropTrainer\n",
    "from pybrain.structure.modules import SoftmaxLayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "net = buildNetwork(113, 400, 2, outclass=SoftmaxLayer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nn_y_train = np.hstack((y_train[:, None], np.logical_not(y_train)[:, None]))\n",
    "nn_y_test = np.hstack((y_test[:, None], np.logical_not(y_test)[:, None]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ds = SupervisedDataSet(train.shape[1], 1)\n",
    "ds.setField('input', train)\n",
    "ds.setField('target', nn_y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trainer = BackpropTrainer(net, dataset=ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.17627569609510868"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "net_preds = []\n",
    "for example in test[:, :]:\n",
    "    net_preds.append(net.activate(example)[0])\n",
    "net_preds = np.array(net_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.561290518885\n"
     ]
    }
   ],
   "source": [
    "print(roc_auc_score(y_test, net_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.03385721,  0.96614279])"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.activate(test[5, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Аггрегация информации о героях"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "matches = features.copy()\n",
    "matches = matches.fillna(0)\n",
    "matches['log_heroes'] = full_logreg_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fields = ['level', 'gold', 'xp', 'lh', 'kills', 'deaths', 'items']\n",
    "teams = ['r', 'd']\n",
    "players = range(1, 6)\n",
    "for field in fields:\n",
    "    for team in teams:\n",
    "        name = team + '_' + field\n",
    "        matches[name] = 0\n",
    "        for player in players:\n",
    "            matches[name] += matches[team + str(player) + '_' + field] \n",
    "            del matches[team + str(player) + '_' + field] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bad_columns = ['start_time', 'duration', 'radiant_win', 'tower_status_dire', 'tower_status_radiant',\n",
    "               'barracks_status_radiant', 'barracks_status_dire', 'first_blood_player1', 'first_blood_player2']\n",
    "categorical_columns = ['lobby_type']\n",
    "for i in range(1, 6):\n",
    "    bad_columns.append('r'+str(i)+'_hero')\n",
    "    bad_columns.append('d'+str(i)+'_hero')\n",
    "#     bad_columns.append()\n",
    "other_cols = [col for col in matches.columns if not (col in categorical_columns)\n",
    "             and not (col in bad_columns)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train, y_train, test, y_test = preprocess(matches, categorical_columns, other_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64820, 36)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dtrain = xgb.DMatrix(train, label=y_train)\n",
    "dtest = xgb.DMatrix(test, label=y_test)\n",
    "param = {'bst:max_depth':3, 'bst:eta':1, 'silent':1, 'objective':'binary:logistic' }\n",
    "param['nthread'] = 4\n",
    "param['eval_metric'] = 'auc'\n",
    "# evallist  = [(dtest,'eval'), (dtrain,'train')]\n",
    "evallist  = [(dtrain,'train')]\n",
    "num_round = 10\n",
    "bst = xgb.train(param, dtrain, num_round)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.72304277696606256"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boost_preds = bst.predict(dtest,ntree_limit=bst.best_ntree_limit)\n",
    "roc_auc_score(y_test, boost_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['lobby_type']"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorical_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Случайный лес"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "forest = RandomForestClassifier(n_estimators=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest.fit(train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "forest_preds = forest.predict_proba(test)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.72392289135457544"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_test, forest_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpha 0.0 :\n",
      "0.723042776966\n",
      "\n",
      "Alpha 0.1 :\n",
      "0.72505828652\n",
      "\n",
      "Alpha 0.2 :\n",
      "0.726769425343\n",
      "\n",
      "Alpha 0.3 :\n",
      "0.72813551037\n",
      "\n",
      "Alpha 0.4 :\n",
      "0.729110148665\n",
      "\n",
      "Alpha 0.5 :\n",
      "0.729646675486\n",
      "\n",
      "Alpha 0.6 :\n",
      "0.729691207881\n",
      "\n",
      "Alpha 0.7 :\n",
      "0.729209325839\n",
      "\n",
      "Alpha 0.8 :\n",
      "0.728175578997\n",
      "\n",
      "Alpha 0.9 :\n",
      "0.72658799388\n",
      "\n",
      "Alpha 1.0 :\n",
      "0.724396835471\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for alpha in np.linspace(0,1,11):\n",
    "    print('Alpha', alpha, ':')\n",
    "    preds = alpha * forest_preds + (1 - alpha) * boost_preds\n",
    "    print(roc_auc_score(y_test, preds))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Сясь"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64820, 36)"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "svm = SVC()\n",
    "svm.fit(train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "svm_preds = svm.predict_proba(test)\n",
    "roc_auc_score(y_test, svm_preds)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
